{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar e processar dados\n",
    "df = pd.read_csv('Dados Históricos - Ibovespa.csv', encoding='utf-8')\n",
    "df['Data'] = pd.to_datetime(df['Data'], format='%d.%m.%Y')\n",
    "df = df.sort_values('Data').reset_index(drop=True)\n",
    "\n",
    "# Converter volume\n",
    "def converter_volume(vol_str):\n",
    "    if pd.isna(vol_str): return np.nan\n",
    "    vol_str = str(vol_str).replace(',', '.')\n",
    "    if 'B' in vol_str: return float(vol_str.replace('B', '')) * 1e9\n",
    "    elif 'M' in vol_str: return float(vol_str.replace('M', '')) * 1e6\n",
    "    elif 'K' in vol_str: return float(vol_str.replace('K', '')) * 1e3\n",
    "    return float(vol_str)\n",
    "\n",
    "df['Volume'] = df['Vol.'].apply(converter_volume)\n",
    "df['Variacao'] = df['Var%'].str.replace('%', '').str.replace(',', '.').astype(float) / 100\n",
    "df['Target'] = (df['Variacao'].shift(-1) > 0).astype(int)\n",
    "df = df[:-1].copy()\n",
    "\n",
    "print(f\"Dataset processado: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar features técnicas\n",
    "df_features = df.copy()\n",
    "\n",
    "# Médias móveis\n",
    "for periodo in [5, 10, 20, 50]:\n",
    "    df_features[f'MA_{periodo}'] = df_features['Último'].rolling(window=periodo).mean()\n",
    "\n",
    "# Bandas de Bollinger\n",
    "df_features['BB_Middle'] = df_features['Último'].rolling(window=20).mean()\n",
    "bb_std = df_features['Último'].rolling(window=20).std()\n",
    "df_features['BB_Upper'] = df_features['BB_Middle'] + (bb_std * 2)\n",
    "df_features['BB_Lower'] = df_features['BB_Middle'] - (bb_std * 2)\n",
    "df_features['BB_Width'] = df_features['BB_Upper'] - df_features['BB_Lower']\n",
    "df_features['BB_Position'] = (df_features['Último'] - df_features['BB_Lower']) / df_features['BB_Width']\n",
    "\n",
    "# RSI\n",
    "def calculate_rsi(prices, window=14):\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "df_features['RSI'] = calculate_rsi(df_features['Último'])\n",
    "\n",
    "# MACD\n",
    "ema_12 = df_features['Último'].ewm(span=12).mean()\n",
    "ema_26 = df_features['Último'].ewm(span=26).mean()\n",
    "df_features['MACD'] = ema_12 - ema_26\n",
    "df_features['Signal_Line'] = df_features['MACD'].ewm(span=9).mean()\n",
    "\n",
    "# ATR\n",
    "df_features['high_low'] = df_features['Máxima'] - df_features['Mínima']\n",
    "df_features['high_close_prev'] = abs(df_features['Máxima'] - df_features['Último'].shift(1))\n",
    "df_features['low_close_prev'] = abs(df_features['Mínima'] - df_features['Último'].shift(1))\n",
    "df_features['true_range'] = df_features[['high_low', 'high_close_prev', 'low_close_prev']].max(axis=1)\n",
    "\n",
    "for periodo in [5, 10, 20]:\n",
    "    df_features[f'atr_{periodo}'] = df_features['true_range'].rolling(window=periodo).mean()\n",
    "\n",
    "# Volatilidade\n",
    "df_features['returns'] = df_features['Último'].pct_change()\n",
    "for periodo in [5, 10, 20]:\n",
    "    df_features[f'volatility_{periodo}'] = df_features['returns'].rolling(window=periodo).std()\n",
    "\n",
    "# Features de preço\n",
    "df_features['Price_Range'] = df_features['Máxima'] - df_features['Mínima']\n",
    "df_features['Price_Position'] = (df_features['Último'] - df_features['Mínima']) / df_features['Price_Range']\n",
    "df_features['Gap'] = df_features['Abertura'] - df_features['Último'].shift(1)\n",
    "df_features['hl_close_ratio'] = (df_features['Máxima'] - df_features['Mínima']) / df_features['Último']\n",
    "\n",
    "# Features temporais\n",
    "df_features['day_of_week'] = df_features['Data'].dt.dayofweek\n",
    "df_features['month'] = df_features['Data'].dt.month\n",
    "df_features['quarter'] = df_features['Data'].dt.quarter\n",
    "df_features['is_month_start'] = (df_features['Data'].dt.day <= 5).astype(int)\n",
    "df_features['is_month_end'] = (df_features['Data'].dt.day >= 25).astype(int)\n",
    "\n",
    "print(f\"Features técnicas criadas: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar correção temporal\n",
    "features_to_shift = [\n",
    "    'Abertura', 'Máxima', 'Mínima', 'Último', 'Volume',\n",
    "    'MA_5', 'MA_10', 'MA_20', 'MA_50',\n",
    "    'BB_Upper', 'BB_Lower', 'BB_Width', 'BB_Position', 'BB_Middle',\n",
    "    'RSI', 'MACD', 'Signal_Line',\n",
    "    'atr_5', 'atr_10', 'atr_20',\n",
    "    'volatility_5', 'volatility_10', 'volatility_20',\n",
    "    'Price_Range', 'Price_Position', 'Gap', 'hl_close_ratio',\n",
    "    'true_range', 'high_close_prev', 'low_close_prev', 'high_low',\n",
    "    'returns', 'Variacao'\n",
    "]\n",
    "\n",
    "features_no_shift = [\n",
    "    'Data', 'day_of_week', 'month', 'quarter',\n",
    "    'is_month_start', 'is_month_end', 'Target'\n",
    "]\n",
    "\n",
    "# Dataset A (Baseline) - sem candlestick\n",
    "dataset_a = pd.DataFrame()\n",
    "for feature in features_no_shift:\n",
    "    if feature in df_features.columns:\n",
    "        dataset_a[feature] = df_features[feature]\n",
    "\n",
    "for feature in features_to_shift:\n",
    "    if feature in df_features.columns:\n",
    "        dataset_a[f'{feature}_shifted'] = df_features[feature].shift(1)\n",
    "\n",
    "dataset_a = dataset_a.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset A (Baseline): {dataset_a.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar features de candlestick\n",
    "dataset_b = dataset_a.copy()\n",
    "\n",
    "# Usar colunas OHLC shifted\n",
    "ohlc_cols = ['Abertura_shifted', 'Máxima_shifted', 'Mínima_shifted', 'Último_shifted']\n",
    "if all(col in dataset_b.columns for col in ohlc_cols):\n",
    "    ohlc_temp = dataset_b[ohlc_cols].copy()\n",
    "    ohlc_temp.columns = ['Open', 'High', 'Low', 'Close']\n",
    "    \n",
    "    # Padrões de candlestick\n",
    "    def detect_doji(df, threshold=0.1):\n",
    "        body_size = abs(df['Close'] - df['Open'])\n",
    "        total_range = df['High'] - df['Low']\n",
    "        return (body_size / total_range < threshold).astype(int)\n",
    "    \n",
    "    def detect_hammer(df):\n",
    "        body_size = abs(df['Close'] - df['Open'])\n",
    "        lower_shadow = df[['Open', 'Close']].min(axis=1) - df['Low']\n",
    "        upper_shadow = df['High'] - df[['Open', 'Close']].max(axis=1)\n",
    "        return ((lower_shadow > 2 * body_size) & (upper_shadow < body_size)).astype(int)\n",
    "    \n",
    "    def detect_shooting_star(df):\n",
    "        body_size = abs(df['Close'] - df['Open'])\n",
    "        lower_shadow = df[['Open', 'Close']].min(axis=1) - df['Low']\n",
    "        upper_shadow = df['High'] - df[['Open', 'Close']].max(axis=1)\n",
    "        return ((upper_shadow > 2 * body_size) & (lower_shadow < body_size)).astype(int)\n",
    "    \n",
    "    def detect_engulfing_bullish(df):\n",
    "        current_bullish = df['Close'] > df['Open']\n",
    "        prev_bearish = (df['Close'].shift(1) < df['Open'].shift(1))\n",
    "        current_open_below_prev_close = df['Open'] < df['Close'].shift(1)\n",
    "        current_close_above_prev_open = df['Close'] > df['Open'].shift(1)\n",
    "        return (current_bullish & prev_bearish & current_open_below_prev_close & current_close_above_prev_open).astype(int)\n",
    "    \n",
    "    # Aplicar padrões\n",
    "    dataset_b['doji_prev'] = detect_doji(ohlc_temp)\n",
    "    dataset_b['hammer_prev'] = detect_hammer(ohlc_temp)\n",
    "    dataset_b['shooting_star_prev'] = detect_shooting_star(ohlc_temp)\n",
    "    dataset_b['engulfing_bullish_prev'] = detect_engulfing_bullish(ohlc_temp)\n",
    "    dataset_b['bullish_candle_prev'] = (ohlc_temp['Close'] > ohlc_temp['Open']).astype(int)\n",
    "    dataset_b['bearish_candle_prev'] = (ohlc_temp['Close'] < ohlc_temp['Open']).astype(int)\n",
    "    dataset_b['body_size_prev'] = abs(ohlc_temp['Close'] - ohlc_temp['Open'])\n",
    "    dataset_b['upper_shadow_prev'] = ohlc_temp['High'] - ohlc_temp[['Open', 'Close']].max(axis=1)\n",
    "    dataset_b['lower_shadow_prev'] = ohlc_temp[['Open', 'Close']].min(axis=1) - ohlc_temp['Low']\n",
    "\n",
    "print(f\"Dataset B (Enriquecido): {dataset_b.shape}\")\n",
    "print(f\"Diferença: +{dataset_b.shape[1] - dataset_a.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar splits temporais\n",
    "def create_temporal_split(df, test_size=0.2):\n",
    "    df_sorted = df.sort_values('Data').reset_index(drop=True) if 'Data' in df.columns else df.copy()\n",
    "    split_idx = int(len(df_sorted) * (1 - test_size))\n",
    "    \n",
    "    train_df = df_sorted.iloc[:split_idx]\n",
    "    test_df = df_sorted.iloc[split_idx:]\n",
    "    \n",
    "    feature_cols = [col for col in df_sorted.columns if col not in ['Data', 'Target']]\n",
    "    \n",
    "    X_train = train_df[feature_cols]\n",
    "    X_test = test_df[feature_cols]\n",
    "    y_train = train_df['Target']\n",
    "    y_test = test_df['Target']\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train_a, X_test_a, y_train_a, y_test_a = create_temporal_split(dataset_a)\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = create_temporal_split(dataset_b)\n",
    "\n",
    "# Remover NaN\n",
    "X_train_a = X_train_a.fillna(method='ffill').fillna(0)\n",
    "X_test_a = X_test_a.fillna(method='ffill').fillna(0)\n",
    "X_train_b = X_train_b.fillna(method='ffill').fillna(0)\n",
    "X_test_b = X_test_b.fillna(method='ffill').fillna(0)\n",
    "\n",
    "print(f\"Dataset A - Train: {X_train_a.shape}, Test: {X_test_a.shape}\")\n",
    "print(f\"Dataset B - Train: {X_train_b.shape}, Test: {X_test_b.shape}\")\n",
    "print(f\"NaN removidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelos\n",
    "models = {\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('logreg', LogisticRegression(C=0.1, solver='liblinear', random_state=42))\n",
    "    ]),\n",
    "    \n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=10, min_samples_split=5,\n",
    "        min_samples_leaf=2, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \n",
    "    'XGBoost': xgb.XGBClassifier(\n",
    "        n_estimators=100, max_depth=6, learning_rate=0.1,\n",
    "        subsample=0.8, colsample_bytree=0.8, random_state=42, eval_metric='logloss'\n",
    "    ),\n",
    "    \n",
    "    'LightGBM': lgb.LGBMClassifier(\n",
    "        n_estimators=100, max_depth=6, learning_rate=0.1,\n",
    "        subsample=0.8, colsample_bytree=0.8, random_state=42, verbose=-1\n",
    "    ),\n",
    "    \n",
    "    'SVM': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(kernel='rbf', probability=True, random_state=42, C=1.0))\n",
    "    ])\n",
    "}\n",
    "\n",
    "print(f\"Modelos preparados: {list(models.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de avaliação\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name, dataset_name):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=tscv, scoring='accuracy')\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'dataset': dataset_name,\n",
    "        'accuracy': accuracy,\n",
    "        'auc_score': auc_score,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'training_time': training_time,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "print(\"Função de avaliação preparada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar olimpíada\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTestando {model_name}...\")\n",
    "    \n",
    "    # Dataset A\n",
    "    try:\n",
    "        result_a = evaluate_model(model, X_train_a, X_test_a, y_train_a, y_test_a, \n",
    "                                model_name, \"Dataset A\")\n",
    "        results.append(result_a)\n",
    "        auc_str_a = f'{result_a[\\\"auc_score\\\"]:.4f}' if result_a['auc_score'] else 'N/A'\n",
    "        print(f'  Dataset A: Acc={result_a[\\\"accuracy\\\"]:.4f}, AUC={auc_str_a}')","\n",
    "    except Exception as e:\n",
    "        print(f\"  Dataset A: Error - {e}\")\n",
    "    \n",
    "    # Dataset B\n",
    "    try:\n",
    "        result_b = evaluate_model(model, X_train_b, X_test_b, y_train_b, y_test_b, \n",
    "                                model_name, \"Dataset B\")\n",
    "        results.append(result_b)\n",
    "        auc_str_b = f'{result_b[\\\"auc_score\\\"]:.4f}' if result_b['auc_score'] else 'N/A'\n",
    "        print(f'  Dataset B: Acc={result_b[\\\"accuracy\\\"]:.4f}, AUC={auc_str_b}')","\n",
    "        \n",
    "        if len(results) >= 2:\n",
    "            diff = result_b['accuracy'] - result_a['accuracy']\n",
    "            print(f\"  Diferença: {diff:+.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Dataset B: Error - {e}\")\n",
    "\n",
    "print(f\"\\nResultados coletados: {len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise dos resultados\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"\\nTabela de Resultados:\")\n",
    "    print(f\"{'Modelo':<20} {'Dataset':<12} {'Accuracy':<10} {'AUC':<8} {'CV Mean':<10} {'Tempo':<8}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    for _, row in results_df.iterrows():\n",
    "        auc_str = f\"{row['auc_score']:.4f}\" if row['auc_score'] is not None else \"N/A\"\n",
    "        print(f\"{row['model_name']:<20} {row['dataset']:<12} {row['accuracy']:<10.4f} {auc_str:<8} {row['cv_mean']:<10.4f} {row['training_time']:<8.2f}\")\n",
    "    \n",
    "    # Ranking por dataset\n",
    "    print(\"\\nRanking Dataset A:\")\n",
    "    dataset_a_results = results_df[results_df['dataset'] == 'Dataset A'].sort_values('accuracy', ascending=False)\n",
    "    for i, (_, row) in enumerate(dataset_a_results.iterrows(), 1):\n",
    "        print(f\"  {i}. {row['model_name']}: {row['accuracy']:.4f}\")\n",
    "    \n",
    "    print(\"\\nRanking Dataset B:\")\n",
    "    dataset_b_results = results_df[results_df['dataset'] == 'Dataset B'].sort_values('accuracy', ascending=False)\n",
    "    for i, (_, row) in enumerate(dataset_b_results.iterrows(), 1):\n",
    "        print(f\"  {i}. {row['model_name']}: {row['accuracy']:.4f}\")\n",
    "    \n",
    "    # Impacto das features de candlestick\n",
    "    print(\"\\nImpacto das Features de Candlestick:\")\n",
    "    candlestick_impact = []\n",
    "    \n",
    "    for model_name in results_df['model_name'].unique():\n",
    "        model_results = results_df[results_df['model_name'] == model_name]\n",
    "        if len(model_results) == 2:\n",
    "            baseline = model_results[model_results['dataset'] == 'Dataset A'].iloc[0]\n",
    "            enriched = model_results[model_results['dataset'] == 'Dataset B'].iloc[0]\n",
    "            \n",
    "            improvement = enriched['accuracy'] - baseline['accuracy']\n",
    "            candlestick_impact.append(improvement)\n",
    "            \n",
    "            print(f\"  {model_name}: {baseline['accuracy']:.4f} -> {enriched['accuracy']:.4f} ({improvement:+.4f})\")\n",
    "    \n",
    "    if candlestick_impact:\n",
    "        avg_improvement = np.mean(candlestick_impact)\n",
    "        positive_count = sum(1 for x in candlestick_impact if x > 0)\n",
    "        \n",
    "        print(f\"\\nResumo do Impacto:\")\n",
    "        print(f\"  Melhoria média: {avg_improvement:+.4f}\")\n",
    "        print(f\"  Modelos que melhoraram: {positive_count}/{len(candlestick_impact)}\")\n",
    "        \n",
    "        if avg_improvement > 0.01:\n",
    "            print(f\"  Conclusão: Features de candlestick agregam valor significativo\")\n",
    "        elif avg_improvement > 0:\n",
    "            print(f\"  Conclusão: Features de candlestick agregam valor marginal\")\n",
    "        else:\n",
    "            print(f\"  Conclusão: Features de candlestick não agregam valor\")\n",
    "    \n",
    "    # Campeão geral\n",
    "    best_result = results_df.loc[results_df['accuracy'].idxmax()]\n",
    "    print(f\"\\nCampeão Geral:\")\n",
    "    print(f\"  Modelo: {best_result['model_name']}\")\n",
    "    print(f\"  Dataset: {best_result['dataset']}\")\n",
    "    print(f\"  Accuracy: {best_result['accuracy']:.4f}\")\n",
    "    print(f\"  AUC: {best_result['auc_score']:.4f}\" if best_result['auc_score'] else \"  AUC: N/A\")\n",
    "\n",
    "else:\n",
    "    print(\"Nenhum resultado coletado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble dos melhores\n",
    "if len(results) >= 6:  # Pelo menos 3 modelos testados em ambos datasets\n",
    "    dataset_b_results = [r for r in results if r['dataset'] == 'Dataset B']\n",
    "    \n",
    "    if len(dataset_b_results) >= 3:\n",
    "        dataset_b_results.sort(key=lambda x: x['accuracy'], reverse=True)\n",
    "        top_3 = dataset_b_results[:3]\n",
    "        \n",
    "        print(f\"\\nTop 3 para ensemble: {[r['model_name'] for r in top_3]}\")\n",
    "        \n",
    "        ensemble_estimators = []\n",
    "        for i, result in enumerate(top_3):\n",
    "            name = f\"model_{i+1}\"\n",
    "            ensemble_estimators.append((name, result['model']))\n",
    "        \n",
    "        voting_classifier = VotingClassifier(estimators=ensemble_estimators, voting='soft')\n",
    "        \n",
    "        try:\n",
    "            ensemble_result = evaluate_model(\n",
    "                voting_classifier, X_train_b, X_test_b, y_train_b, y_test_b,\n",
    "                \"Voting Classifier\", \"Dataset B\"\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nEnsemble Result:\")\n",
    "            print(f\"  Accuracy: {ensemble_result['accuracy']:.4f}\")\n",
    "            print(f\"  AUC: {ensemble_result['auc_score']:.4f}\")\n",
    "            \n",
    "            best_individual = top_3[0]\n",
    "            improvement = ensemble_result['accuracy'] - best_individual['accuracy']\n",
    "            print(f\"  vs Best Individual: {improvement:+.4f}\")\n",
    "            \n",
    "            results.append(ensemble_result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ensemble error: {e}\")\n",
    "\n",
    "print(\"\\nOlimpíada concluída\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização simples\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Gráfico de accuracy por modelo e dataset\n",
    "    plt.subplot(2, 2, 1)\n",
    "    models_list = results_df['model_name'].unique()\n",
    "    datasets_list = results_df['dataset'].unique()\n",
    "    \n",
    "    x = np.arange(len(models_list))\n",
    "    width = 0.35\n",
    "    \n",
    "    for i, dataset in enumerate(datasets_list):\n",
    "        dataset_data = results_df[results_df['dataset'] == dataset]\n",
    "        accuracies = []\n",
    "        \n",
    "        for model in models_list:\n",
    "            model_data = dataset_data[dataset_data['model_name'] == model]\n",
    "            if len(model_data) > 0:\n",
    "                accuracies.append(model_data.iloc[0]['accuracy'])\n",
    "            else:\n",
    "                accuracies.append(0)\n",
    "        \n",
    "        plt.bar(x + i*width, accuracies, width, label=dataset, alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Modelos')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy por Modelo e Dataset')\n",
    "    plt.xticks(x + width/2, models_list, rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Tempo vs Accuracy\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.scatter([r['training_time'] for r in results], \n",
    "               [r['accuracy'] for r in results], alpha=0.7)\n",
    "    plt.xlabel('Tempo de Treinamento (s)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs Tempo')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Distribuição de AUC\n",
    "    plt.subplot(2, 2, 3)\n",
    "    auc_scores = [r['auc_score'] for r in results if r['auc_score'] is not None]\n",
    "    if auc_scores:\n",
    "        plt.hist(auc_scores, bins=10, alpha=0.7, edgecolor='black')\n",
    "        plt.xlabel('AUC Score')\n",
    "        plt.ylabel('Frequência')\n",
    "        plt.title('Distribuição AUC')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Impacto candlestick\n",
    "    plt.subplot(2, 2, 4)\n",
    "    if 'candlestick_impact' in locals() and candlestick_impact:\n",
    "        models_impact = [results_df[results_df['model_name'] == model]['model_name'].iloc[0] \n",
    "                        for model in results_df['model_name'].unique() \n",
    "                        if len(results_df[results_df['model_name'] == model]) == 2]\n",
    "        \n",
    "        if len(models_impact) == len(candlestick_impact):\n",
    "            colors = ['green' if x > 0 else 'red' for x in candlestick_impact]\n",
    "            plt.bar(models_impact, candlestick_impact, color=colors, alpha=0.7)\n",
    "            plt.xlabel('Modelos')\n",
    "            plt.ylabel('Melhoria Accuracy')\n",
    "            plt.title('Impacto Features Candlestick')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Análise visual concluída\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
