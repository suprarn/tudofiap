{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš¨ PIPELINE EXPLÃCITO: RASTREAMENTO COMPLETO DE FEATURES\n",
    "\n",
    "## EstratÃ©gia de CorreÃ§Ã£o:\n",
    "1. **Pipeline ExplÃ­cito**: Cada dataframe tem nome Ãºnico e descritivo\n",
    "2. **Auditoria de Penhascos**: Identificar exatamente onde features sÃ£o perdidas\n",
    "3. **Checkpoints com .info()**: InspeÃ§Ã£o detalhada em cada etapa\n",
    "4. **PreservaÃ§Ã£o Rigorosa**: Garantir que nenhuma feature seja perdida\n",
    "\n",
    "## Nomenclatura do Pipeline:\n",
    "- `df_step01_raw`: Dados brutos carregados\n",
    "- `df_step02_processed`: Dados processados bÃ¡sicos\n",
    "- `df_step03_features`: Com features tÃ©cnicas criadas\n",
    "- `df_step04_selected`: ApÃ³s seleÃ§Ã£o de features\n",
    "- `df_step05_temporal`: ApÃ³s correÃ§Ã£o temporal\n",
    "- `df_step06_candlestick`: Com padrÃµes de candlestick\n",
    "- `df_step07_final`: Dataset final para modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FunÃ§Ã£o de auditoria rigorosa criada\n",
      "ğŸ“‹ Pronta para rastrear cada etapa do pipeline\n"
     ]
    }
   ],
   "source": [
    "# FUNÃ‡ÃƒO DE AUDITORIA RIGOROSA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def audit_pipeline_step(df, step_name, expected_min_cols=None, previous_df=None):\n",
    "    \"\"\"\n",
    "    Auditoria rigorosa de cada etapa do pipeline\n",
    "    Identifica exatamente onde features sÃ£o perdidas\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ” AUDITORIA: {step_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # InformaÃ§Ãµes bÃ¡sicas\n",
    "    print(f\"ğŸ“Š INFORMAÃ‡Ã•ES BÃSICAS:\")\n",
    "    print(f\"   Shape: {df.shape}\")\n",
    "    print(f\"   MemÃ³ria: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Usar .info() para inspeÃ§Ã£o detalhada\n",
    "    print(f\"\\nğŸ“‹ DETALHES DAS COLUNAS (.info()):\")\n",
    "    df.info()\n",
    "    \n",
    "    # CategorizaÃ§Ã£o de features\n",
    "    ohlc_cols = [col for col in df.columns if col in ['Abertura', 'MÃ¡xima', 'MÃ­nima', 'Ãšltimo', 'Volume']]\n",
    "    temporal_cols = [col for col in df.columns if any(x in col.lower() for x in ['data', 'day', 'month', 'quarter', 'year'])]\n",
    "    technical_cols = [col for col in df.columns if any(x in col.lower() for x in ['ma_', 'bb_', 'rsi', 'atr', 'volatility', 'macd'])]\n",
    "    shifted_cols = [col for col in df.columns if col.endswith('_shifted')]\n",
    "    candlestick_cols = [col for col in df.columns if any(x in col.lower() for x in ['doji', 'hammer', 'engulf', 'marubozu', 'shooting', '_prev'])]\n",
    "    target_cols = [col for col in df.columns if 'target' in col.lower()]\n",
    "    other_cols = [col for col in df.columns if col not in ohlc_cols + temporal_cols + technical_cols + shifted_cols + candlestick_cols + target_cols]\n",
    "    \n",
    "    print(f\"\\nğŸ“‚ CATEGORIZAÃ‡ÃƒO DE FEATURES:\")\n",
    "    print(f\"   ğŸ¢ OHLC/Volume ({len(ohlc_cols)}): {ohlc_cols}\")\n",
    "    print(f\"   ğŸ“… Temporais ({len(temporal_cols)}): {temporal_cols}\")\n",
    "    print(f\"   ğŸ“ˆ TÃ©cnicas ({len(technical_cols)}): {technical_cols[:5]}{'...' if len(technical_cols) > 5 else ''}\")\n",
    "    print(f\"   â° Shifted ({len(shifted_cols)}): {shifted_cols[:5]}{'...' if len(shifted_cols) > 5 else ''}\")\n",
    "    print(f\"   ğŸ•¯ï¸ Candlestick ({len(candlestick_cols)}): {candlestick_cols[:5]}{'...' if len(candlestick_cols) > 5 else ''}\")\n",
    "    print(f\"   ğŸ¯ Target ({len(target_cols)}): {target_cols}\")\n",
    "    print(f\"   â“ Outras ({len(other_cols)}): {other_cols[:5]}{'...' if len(other_cols) > 5 else ''}\")\n",
    "    \n",
    "    # Verificar se hÃ¡ perda de features\n",
    "    if previous_df is not None:\n",
    "        print(f\"\\nğŸš¨ ANÃLISE DE MUDANÃ‡AS:\")\n",
    "        prev_cols = set(previous_df.columns)\n",
    "        curr_cols = set(df.columns)\n",
    "        \n",
    "        lost_features = prev_cols - curr_cols\n",
    "        gained_features = curr_cols - prev_cols\n",
    "        \n",
    "        print(f\"   ğŸ“‰ Features PERDIDAS ({len(lost_features)}):\")\n",
    "        if lost_features:\n",
    "            for feature in sorted(lost_features):\n",
    "                print(f\"      âŒ {feature}\")\n",
    "        else:\n",
    "            print(f\"      âœ… Nenhuma feature perdida\")\n",
    "        \n",
    "        print(f\"   ğŸ“ˆ Features GANHAS ({len(gained_features)}):\")\n",
    "        if gained_features:\n",
    "            for feature in sorted(gained_features):\n",
    "                print(f\"      âœ… {feature}\")\n",
    "        else:\n",
    "            print(f\"      â– Nenhuma feature ganha\")\n",
    "        \n",
    "        net_change = len(curr_cols) - len(prev_cols)\n",
    "        print(f\"   ğŸ“Š MudanÃ§a lÃ­quida: {net_change:+d} features\")\n",
    "        \n",
    "        # ALERTA para perdas significativas\n",
    "        if len(lost_features) > 5:\n",
    "            print(f\"\\nğŸš¨ ALERTA: PERDA SIGNIFICATIVA DE FEATURES!\")\n",
    "            print(f\"   {len(lost_features)} features foram perdidas nesta etapa\")\n",
    "            print(f\"   Isso pode indicar um 'PENHASCO' no pipeline\")\n",
    "    \n",
    "    # Verificar expectativas\n",
    "    if expected_min_cols and len(df.columns) < expected_min_cols:\n",
    "        print(f\"\\nâš ï¸ AVISO: Menos colunas que esperado\")\n",
    "        print(f\"   Esperado: >= {expected_min_cols}\")\n",
    "        print(f\"   Atual: {len(df.columns)}\")\n",
    "    \n",
    "    # Verificar qualidade dos dados\n",
    "    print(f\"\\nğŸ” QUALIDADE DOS DADOS:\")\n",
    "    null_counts = df.isnull().sum()\n",
    "    cols_with_nulls = null_counts[null_counts > 0]\n",
    "    print(f\"   Colunas com valores ausentes: {len(cols_with_nulls)}\")\n",
    "    if len(cols_with_nulls) > 0:\n",
    "        print(f\"   Top 5 com mais NaNs:\")\n",
    "        for col, count in cols_with_nulls.head().items():\n",
    "            print(f\"      {col}: {count} ({count/len(df):.1%})\")\n",
    "    \n",
    "    print(f\"\\nâœ… Auditoria de {step_name} concluÃ­da\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return {\n",
    "        'step_name': step_name,\n",
    "        'shape': df.shape,\n",
    "        'columns': list(df.columns),\n",
    "        'ohlc_count': len(ohlc_cols),\n",
    "        'technical_count': len(technical_cols),\n",
    "        'shifted_count': len(shifted_cols),\n",
    "        'candlestick_count': len(candlestick_cols)\n",
    "    }\n",
    "\n",
    "print(\"âœ… FunÃ§Ã£o de auditoria rigorosa criada\")\n",
    "print(\"ğŸ“‹ Pronta para rastrear cada etapa do pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 01: CARREGAMENTO DOS DADOS BRUTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ INICIANDO PIPELINE EXPLÃCITO\n",
      "ğŸ“‚ STEP 01: Carregando dados brutos...\n",
      "\n",
      "============================================================\n",
      "ğŸ” AUDITORIA: STEP 01 - DADOS BRUTOS\n",
      "============================================================\n",
      "ğŸ“Š INFORMAÃ‡Ã•ES BÃSICAS:\n",
      "   Shape: (3592, 7)\n",
      "   MemÃ³ria: 0.68 MB\n",
      "\n",
      "ğŸ“‹ DETALHES DAS COLUNAS (.info()):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3592 entries, 0 to 3591\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Data      3592 non-null   object \n",
      " 1   Ãšltimo    3592 non-null   float64\n",
      " 2   Abertura  3592 non-null   float64\n",
      " 3   MÃ¡xima    3592 non-null   float64\n",
      " 4   MÃ­nima    3592 non-null   float64\n",
      " 5   Vol.      3591 non-null   object \n",
      " 6   Var%      3592 non-null   object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 196.6+ KB\n",
      "\n",
      "ğŸ“‚ CATEGORIZAÃ‡ÃƒO DE FEATURES:\n",
      "   ğŸ¢ OHLC/Volume (4): ['Ãšltimo', 'Abertura', 'MÃ¡xima', 'MÃ­nima']\n",
      "   ğŸ“… Temporais (1): ['Data']\n",
      "   ğŸ“ˆ TÃ©cnicas (0): []\n",
      "   â° Shifted (0): []\n",
      "   ğŸ•¯ï¸ Candlestick (0): []\n",
      "   ğŸ¯ Target (0): []\n",
      "   â“ Outras (2): ['Vol.', 'Var%']\n",
      "\n",
      "ğŸ” QUALIDADE DOS DADOS:\n",
      "   Colunas com valores ausentes: 1\n",
      "   Top 5 com mais NaNs:\n",
      "      Vol.: 1 (0.0%)\n",
      "\n",
      "âœ… Auditoria de STEP 01 - Dados Brutos concluÃ­da\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ RESUMO STEP 01:\n",
      "   âœ… Dados carregados: (3592, 7)\n",
      "   ğŸ“Š Colunas originais: ['Data', 'Ãšltimo', 'Abertura', 'MÃ¡xima', 'MÃ­nima', 'Vol.', 'Var%']\n"
     ]
    }
   ],
   "source": [
    "# STEP 01: CARREGAMENTO DOS DADOS BRUTOS\n",
    "print(\"ğŸš€ INICIANDO PIPELINE EXPLÃCITO\")\n",
    "print(\"ğŸ“‚ STEP 01: Carregando dados brutos...\")\n",
    "\n",
    "# Carregar dados brutos\n",
    "df_step01_raw = pd.read_csv('Dados HistÃ³ricos - Ibovespa.csv', encoding='utf-8')\n",
    "\n",
    "# Auditoria do carregamento\n",
    "audit_step01 = audit_pipeline_step(df_step01_raw, \"STEP 01 - Dados Brutos\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ RESUMO STEP 01:\")\n",
    "print(f\"   âœ… Dados carregados: {df_step01_raw.shape}\")\n",
    "print(f\"   ğŸ“Š Colunas originais: {list(df_step01_raw.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 02: PROCESSAMENTO BÃSICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‚ STEP 02: Processamento bÃ¡sico...\n",
      "\n",
      "============================================================\n",
      "ğŸ” AUDITORIA: STEP 02 - PROCESSAMENTO BÃSICO\n",
      "============================================================\n",
      "ğŸ“Š INFORMAÃ‡Ã•ES BÃSICAS:\n",
      "   Shape: (3591, 10)\n",
      "   MemÃ³ria: 0.59 MB\n",
      "\n",
      "ğŸ“‹ DETALHES DAS COLUNAS (.info()):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3591 entries, 0 to 3590\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Data      3591 non-null   datetime64[ns]\n",
      " 1   Ãšltimo    3591 non-null   float64       \n",
      " 2   Abertura  3591 non-null   float64       \n",
      " 3   MÃ¡xima    3591 non-null   float64       \n",
      " 4   MÃ­nima    3591 non-null   float64       \n",
      " 5   Vol.      3591 non-null   object        \n",
      " 6   Var%      3591 non-null   object        \n",
      " 7   Volume    3591 non-null   float64       \n",
      " 8   Variacao  3591 non-null   float64       \n",
      " 9   Target    3591 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(6), int64(1), object(2)\n",
      "memory usage: 280.7+ KB\n",
      "\n",
      "ğŸ“‚ CATEGORIZAÃ‡ÃƒO DE FEATURES:\n",
      "   ğŸ¢ OHLC/Volume (5): ['Ãšltimo', 'Abertura', 'MÃ¡xima', 'MÃ­nima', 'Volume']\n",
      "   ğŸ“… Temporais (1): ['Data']\n",
      "   ğŸ“ˆ TÃ©cnicas (0): []\n",
      "   â° Shifted (0): []\n",
      "   ğŸ•¯ï¸ Candlestick (0): []\n",
      "   ğŸ¯ Target (1): ['Target']\n",
      "   â“ Outras (3): ['Vol.', 'Var%', 'Variacao']\n",
      "\n",
      "ğŸš¨ ANÃLISE DE MUDANÃ‡AS:\n",
      "   ğŸ“‰ Features PERDIDAS (0):\n",
      "      âœ… Nenhuma feature perdida\n",
      "   ğŸ“ˆ Features GANHAS (3):\n",
      "      âœ… Target\n",
      "      âœ… Variacao\n",
      "      âœ… Volume\n",
      "   ğŸ“Š MudanÃ§a lÃ­quida: +3 features\n",
      "\n",
      "ğŸ” QUALIDADE DOS DADOS:\n",
      "   Colunas com valores ausentes: 0\n",
      "\n",
      "âœ… Auditoria de STEP 02 - Processamento BÃ¡sico concluÃ­da\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ RESUMO STEP 02:\n",
      "   âœ… Target criado corretamente\n",
      "   ğŸ“Š Shape apÃ³s processamento: (3591, 10)\n",
      "   ğŸ¯ DistribuiÃ§Ã£o do target:\n",
      "Target\n",
      "1    0.510721\n",
      "0    0.489279\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# STEP 02: PROCESSAMENTO BÃSICO\n",
    "print(\"\\nğŸ“‚ STEP 02: Processamento bÃ¡sico...\")\n",
    "\n",
    "# Criar cÃ³pia para processamento\n",
    "df_step02_processed = df_step01_raw.copy()\n",
    "\n",
    "# Processamento de data\n",
    "df_step02_processed['Data'] = pd.to_datetime(df_step02_processed['Data'], format='%d.%m.%Y')\n",
    "df_step02_processed = df_step02_processed.sort_values('Data').reset_index(drop=True)\n",
    "\n",
    "# Tratar valores ausentes\n",
    "df_step02_processed['Vol.'] = df_step02_processed['Vol.'].fillna(method='ffill')\n",
    "\n",
    "# Converter Volume para numÃ©rico\n",
    "def converter_volume(vol_str):\n",
    "    if pd.isna(vol_str): return np.nan\n",
    "    vol_str = str(vol_str).replace(',', '.')\n",
    "    if 'B' in vol_str: return float(vol_str.replace('B', '')) * 1e9\n",
    "    elif 'M' in vol_str: return float(vol_str.replace('M', '')) * 1e6\n",
    "    elif 'K' in vol_str: return float(vol_str.replace('K', '')) * 1e3\n",
    "    return float(vol_str)\n",
    "\n",
    "df_step02_processed['Volume'] = df_step02_processed['Vol.'].apply(converter_volume)\n",
    "df_step02_processed['Variacao'] = df_step02_processed['Var%'].str.replace('%', '').str.replace(',', '.').astype(float) / 100\n",
    "\n",
    "# Criar target\n",
    "df_step02_processed['Target'] = (df_step02_processed['Variacao'].shift(-1) > 0).astype(int)\n",
    "df_step02_processed = df_step02_processed[:-1].copy()  # Remove Ãºltima linha\n",
    "\n",
    "# Auditoria do processamento\n",
    "audit_step02 = audit_pipeline_step(\n",
    "    df_step02_processed, \n",
    "    \"STEP 02 - Processamento BÃ¡sico\", \n",
    "    expected_min_cols=len(df_step01_raw.columns),\n",
    "    previous_df=df_step01_raw\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“‹ RESUMO STEP 02:\")\n",
    "print(f\"   âœ… Target criado corretamente\")\n",
    "print(f\"   ğŸ“Š Shape apÃ³s processamento: {df_step02_processed.shape}\")\n",
    "print(f\"   ğŸ¯ DistribuiÃ§Ã£o do target:\")\n",
    "print(df_step02_processed['Target'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 03: CRIAÃ‡ÃƒO DE FEATURES TÃ‰CNICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‚ STEP 03: Criando features tÃ©cnicas...\n",
      "ğŸ“ˆ Criando indicadores tÃ©cnicos...\n",
      "\n",
      "============================================================\n",
      "ğŸ” AUDITORIA: STEP 03 - FEATURES TÃ‰CNICAS\n",
      "============================================================\n",
      "ğŸ“Š INFORMAÃ‡Ã•ES BÃSICAS:\n",
      "   Shape: (3591, 44)\n",
      "   MemÃ³ria: 1.47 MB\n",
      "\n",
      "ğŸ“‹ DETALHES DAS COLUNAS (.info()):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3591 entries, 0 to 3590\n",
      "Data columns (total 44 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Data             3591 non-null   datetime64[ns]\n",
      " 1   Ãšltimo           3591 non-null   float64       \n",
      " 2   Abertura         3591 non-null   float64       \n",
      " 3   MÃ¡xima           3591 non-null   float64       \n",
      " 4   MÃ­nima           3591 non-null   float64       \n",
      " 5   Vol.             3591 non-null   object        \n",
      " 6   Var%             3591 non-null   object        \n",
      " 7   Volume           3591 non-null   float64       \n",
      " 8   Variacao         3591 non-null   float64       \n",
      " 9   Target           3591 non-null   int64         \n",
      " 10  MA_5             3587 non-null   float64       \n",
      " 11  MA_10            3582 non-null   float64       \n",
      " 12  MA_20            3572 non-null   float64       \n",
      " 13  MA_50            3542 non-null   float64       \n",
      " 14  BB_Middle        3572 non-null   float64       \n",
      " 15  BB_Upper         3572 non-null   float64       \n",
      " 16  BB_Lower         3572 non-null   float64       \n",
      " 17  BB_Width         3572 non-null   float64       \n",
      " 18  BB_Position      3572 non-null   float64       \n",
      " 19  RSI              3578 non-null   float64       \n",
      " 20  MACD             3591 non-null   float64       \n",
      " 21  Signal_Line      3591 non-null   float64       \n",
      " 22  high_low         3591 non-null   float64       \n",
      " 23  high_close_prev  3590 non-null   float64       \n",
      " 24  low_close_prev   3590 non-null   float64       \n",
      " 25  true_range       3591 non-null   float64       \n",
      " 26  atr_5            3587 non-null   float64       \n",
      " 27  atr_10           3582 non-null   float64       \n",
      " 28  atr_20           3572 non-null   float64       \n",
      " 29  returns          3590 non-null   float64       \n",
      " 30  volatility_5     3586 non-null   float64       \n",
      " 31  volatility_10    3581 non-null   float64       \n",
      " 32  volatility_20    3571 non-null   float64       \n",
      " 33  Price_Range      3591 non-null   float64       \n",
      " 34  Price_Position   3591 non-null   float64       \n",
      " 35  Gap              3590 non-null   float64       \n",
      " 36  hl_close_ratio   3591 non-null   float64       \n",
      " 37  day_of_week      3591 non-null   int32         \n",
      " 38  month            3591 non-null   int32         \n",
      " 39  quarter          3591 non-null   int32         \n",
      " 40  year             3591 non-null   int32         \n",
      " 41  is_month_start   3591 non-null   int64         \n",
      " 42  is_month_end     3591 non-null   int64         \n",
      " 43  is_quarter_end   3591 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(33), int32(4), int64(4), object(2)\n",
      "memory usage: 1.2+ MB\n",
      "\n",
      "ğŸ“‚ CATEGORIZAÃ‡ÃƒO DE FEATURES:\n",
      "   ğŸ¢ OHLC/Volume (5): ['Ãšltimo', 'Abertura', 'MÃ¡xima', 'MÃ­nima', 'Volume']\n",
      "   ğŸ“… Temporais (8): ['Data', 'day_of_week', 'month', 'quarter', 'year', 'is_month_start', 'is_month_end', 'is_quarter_end']\n",
      "   ğŸ“ˆ TÃ©cnicas (17): ['MA_5', 'MA_10', 'MA_20', 'MA_50', 'BB_Middle']...\n",
      "   â° Shifted (0): []\n",
      "   ğŸ•¯ï¸ Candlestick (2): ['high_close_prev', 'low_close_prev']\n",
      "   ğŸ¯ Target (1): ['Target']\n",
      "   â“ Outras (11): ['Vol.', 'Var%', 'Variacao', 'Signal_Line', 'high_low']...\n",
      "\n",
      "ğŸš¨ ANÃLISE DE MUDANÃ‡AS:\n",
      "   ğŸ“‰ Features PERDIDAS (0):\n",
      "      âœ… Nenhuma feature perdida\n",
      "   ğŸ“ˆ Features GANHAS (34):\n",
      "      âœ… BB_Lower\n",
      "      âœ… BB_Middle\n",
      "      âœ… BB_Position\n",
      "      âœ… BB_Upper\n",
      "      âœ… BB_Width\n",
      "      âœ… Gap\n",
      "      âœ… MACD\n",
      "      âœ… MA_10\n",
      "      âœ… MA_20\n",
      "      âœ… MA_5\n",
      "      âœ… MA_50\n",
      "      âœ… Price_Position\n",
      "      âœ… Price_Range\n",
      "      âœ… RSI\n",
      "      âœ… Signal_Line\n",
      "      âœ… atr_10\n",
      "      âœ… atr_20\n",
      "      âœ… atr_5\n",
      "      âœ… day_of_week\n",
      "      âœ… high_close_prev\n",
      "      âœ… high_low\n",
      "      âœ… hl_close_ratio\n",
      "      âœ… is_month_end\n",
      "      âœ… is_month_start\n",
      "      âœ… is_quarter_end\n",
      "      âœ… low_close_prev\n",
      "      âœ… month\n",
      "      âœ… quarter\n",
      "      âœ… returns\n",
      "      âœ… true_range\n",
      "      âœ… volatility_10\n",
      "      âœ… volatility_20\n",
      "      âœ… volatility_5\n",
      "      âœ… year\n",
      "   ğŸ“Š MudanÃ§a lÃ­quida: +34 features\n",
      "\n",
      "ğŸ” QUALIDADE DOS DADOS:\n",
      "   Colunas com valores ausentes: 20\n",
      "   Top 5 com mais NaNs:\n",
      "      MA_5: 4 (0.1%)\n",
      "      MA_10: 9 (0.3%)\n",
      "      MA_20: 19 (0.5%)\n",
      "      MA_50: 49 (1.4%)\n",
      "      BB_Middle: 19 (0.5%)\n",
      "\n",
      "âœ… Auditoria de STEP 03 - Features TÃ©cnicas concluÃ­da\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ RESUMO STEP 03:\n",
      "   âœ… Features tÃ©cnicas criadas: 34\n",
      "   ğŸ“Š Total de features: 44\n",
      "   ğŸ¯ Shape final: (3591, 44)\n"
     ]
    }
   ],
   "source": [
    "# STEP 03: CRIAÃ‡ÃƒO DE FEATURES TÃ‰CNICAS\n",
    "print(\"\\nğŸ“‚ STEP 03: Criando features tÃ©cnicas...\")\n",
    "\n",
    "# Criar cÃ³pia para features\n",
    "df_step03_features = df_step02_processed.copy()\n",
    "\n",
    "print(\"ğŸ“ˆ Criando indicadores tÃ©cnicos...\")\n",
    "\n",
    "# MÃ©dias mÃ³veis\n",
    "for periodo in [5, 10, 20, 50]:\n",
    "    df_step03_features[f'MA_{periodo}'] = df_step03_features['Ãšltimo'].rolling(window=periodo).mean()\n",
    "\n",
    "# Bandas de Bollinger\n",
    "df_step03_features['BB_Middle'] = df_step03_features['Ãšltimo'].rolling(window=20).mean()\n",
    "bb_std = df_step03_features['Ãšltimo'].rolling(window=20).std()\n",
    "df_step03_features['BB_Upper'] = df_step03_features['BB_Middle'] + (bb_std * 2)\n",
    "df_step03_features['BB_Lower'] = df_step03_features['BB_Middle'] - (bb_std * 2)\n",
    "df_step03_features['BB_Width'] = df_step03_features['BB_Upper'] - df_step03_features['BB_Lower']\n",
    "df_step03_features['BB_Position'] = (df_step03_features['Ãšltimo'] - df_step03_features['BB_Lower']) / df_step03_features['BB_Width']\n",
    "\n",
    "# RSI\n",
    "def calculate_rsi(prices, window=14):\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "df_step03_features['RSI'] = calculate_rsi(df_step03_features['Ãšltimo'])\n",
    "\n",
    "# MACD\n",
    "ema_12 = df_step03_features['Ãšltimo'].ewm(span=12).mean()\n",
    "ema_26 = df_step03_features['Ãšltimo'].ewm(span=26).mean()\n",
    "df_step03_features['MACD'] = ema_12 - ema_26\n",
    "df_step03_features['Signal_Line'] = df_step03_features['MACD'].ewm(span=9).mean()\n",
    "\n",
    "# ATR (Average True Range)\n",
    "df_step03_features['high_low'] = df_step03_features['MÃ¡xima'] - df_step03_features['MÃ­nima']\n",
    "df_step03_features['high_close_prev'] = abs(df_step03_features['MÃ¡xima'] - df_step03_features['Ãšltimo'].shift(1))\n",
    "df_step03_features['low_close_prev'] = abs(df_step03_features['MÃ­nima'] - df_step03_features['Ãšltimo'].shift(1))\n",
    "df_step03_features['true_range'] = df_step03_features[['high_low', 'high_close_prev', 'low_close_prev']].max(axis=1)\n",
    "\n",
    "for periodo in [5, 10, 20]:\n",
    "    df_step03_features[f'atr_{periodo}'] = df_step03_features['true_range'].rolling(window=periodo).mean()\n",
    "\n",
    "# Volatilidade\n",
    "df_step03_features['returns'] = df_step03_features['Ãšltimo'].pct_change()\n",
    "for periodo in [5, 10, 20]:\n",
    "    df_step03_features[f'volatility_{periodo}'] = df_step03_features['returns'].rolling(window=periodo).std()\n",
    "\n",
    "# Features de preÃ§o\n",
    "df_step03_features['Price_Range'] = df_step03_features['MÃ¡xima'] - df_step03_features['MÃ­nima']\n",
    "df_step03_features['Price_Position'] = (df_step03_features['Ãšltimo'] - df_step03_features['MÃ­nima']) / df_step03_features['Price_Range']\n",
    "df_step03_features['Gap'] = df_step03_features['Abertura'] - df_step03_features['Ãšltimo'].shift(1)\n",
    "df_step03_features['hl_close_ratio'] = (df_step03_features['MÃ¡xima'] - df_step03_features['MÃ­nima']) / df_step03_features['Ãšltimo']\n",
    "\n",
    "# Features temporais\n",
    "df_step03_features['day_of_week'] = df_step03_features['Data'].dt.dayofweek\n",
    "df_step03_features['month'] = df_step03_features['Data'].dt.month\n",
    "df_step03_features['quarter'] = df_step03_features['Data'].dt.quarter\n",
    "df_step03_features['year'] = df_step03_features['Data'].dt.year\n",
    "df_step03_features['is_month_start'] = (df_step03_features['Data'].dt.day <= 5).astype(int)\n",
    "df_step03_features['is_month_end'] = (df_step03_features['Data'].dt.day >= 25).astype(int)\n",
    "df_step03_features['is_quarter_end'] = df_step03_features['Data'].dt.is_quarter_end.astype(int)\n",
    "\n",
    "# Auditoria da criaÃ§Ã£o de features\n",
    "audit_step03 = audit_pipeline_step(\n",
    "    df_step03_features, \n",
    "    \"STEP 03 - Features TÃ©cnicas\", \n",
    "    expected_min_cols=30,  # Esperamos pelo menos 30 features\n",
    "    previous_df=df_step02_processed\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“‹ RESUMO STEP 03:\")\n",
    "print(f\"   âœ… Features tÃ©cnicas criadas: {df_step03_features.shape[1] - df_step02_processed.shape[1]}\")\n",
    "print(f\"   ğŸ“Š Total de features: {df_step03_features.shape[1]}\")\n",
    "print(f\"   ğŸ¯ Shape final: {df_step03_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 04: SELEÃ‡ÃƒO DE FEATURES (PONTO CRÃTICO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‚ STEP 04: SeleÃ§Ã£o de features (PONTO CRÃTICO)...\n",
      "ğŸš¨ ATENÃ‡ÃƒO: Esta Ã© uma Ã¡rea comum para 'PENHASCOS' de features!\n",
      "\n",
      "ğŸ” CHECKPOINT ANTES DA SELEÃ‡ÃƒO:\n",
      "   Features disponÃ­veis: 44\n",
      "   Primeiras 10: ['Data', 'Ãšltimo', 'Abertura', 'MÃ¡xima', 'MÃ­nima', 'Vol.', 'Var%', 'Volume', 'Variacao', 'Target']\n",
      "   Ãšltimas 10: ['Price_Position', 'Gap', 'hl_close_ratio', 'day_of_week', 'month', 'quarter', 'year', 'is_month_start', 'is_month_end', 'is_quarter_end']\n",
      "\n",
      "ğŸ—‘ï¸ Removendo apenas colunas auxiliares: ['Vol.', 'Var%', 'high_low', 'BB_Middle']\n",
      "\n",
      "âœ… Todas as features importantes preservadas\n",
      "\n",
      "============================================================\n",
      "ğŸ” AUDITORIA: STEP 04 - SELEÃ‡ÃƒO DE FEATURES\n",
      "============================================================\n",
      "ğŸ“Š INFORMAÃ‡Ã•ES BÃSICAS:\n",
      "   Shape: (3591, 40)\n",
      "   MemÃ³ria: 1.04 MB\n",
      "\n",
      "ğŸ“‹ DETALHES DAS COLUNAS (.info()):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3591 entries, 0 to 3590\n",
      "Data columns (total 40 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Data             3591 non-null   datetime64[ns]\n",
      " 1   Ãšltimo           3591 non-null   float64       \n",
      " 2   Abertura         3591 non-null   float64       \n",
      " 3   MÃ¡xima           3591 non-null   float64       \n",
      " 4   MÃ­nima           3591 non-null   float64       \n",
      " 5   Volume           3591 non-null   float64       \n",
      " 6   Variacao         3591 non-null   float64       \n",
      " 7   Target           3591 non-null   int64         \n",
      " 8   MA_5             3587 non-null   float64       \n",
      " 9   MA_10            3582 non-null   float64       \n",
      " 10  MA_20            3572 non-null   float64       \n",
      " 11  MA_50            3542 non-null   float64       \n",
      " 12  BB_Upper         3572 non-null   float64       \n",
      " 13  BB_Lower         3572 non-null   float64       \n",
      " 14  BB_Width         3572 non-null   float64       \n",
      " 15  BB_Position      3572 non-null   float64       \n",
      " 16  RSI              3578 non-null   float64       \n",
      " 17  MACD             3591 non-null   float64       \n",
      " 18  Signal_Line      3591 non-null   float64       \n",
      " 19  high_close_prev  3590 non-null   float64       \n",
      " 20  low_close_prev   3590 non-null   float64       \n",
      " 21  true_range       3591 non-null   float64       \n",
      " 22  atr_5            3587 non-null   float64       \n",
      " 23  atr_10           3582 non-null   float64       \n",
      " 24  atr_20           3572 non-null   float64       \n",
      " 25  returns          3590 non-null   float64       \n",
      " 26  volatility_5     3586 non-null   float64       \n",
      " 27  volatility_10    3581 non-null   float64       \n",
      " 28  volatility_20    3571 non-null   float64       \n",
      " 29  Price_Range      3591 non-null   float64       \n",
      " 30  Price_Position   3591 non-null   float64       \n",
      " 31  Gap              3590 non-null   float64       \n",
      " 32  hl_close_ratio   3591 non-null   float64       \n",
      " 33  day_of_week      3591 non-null   int32         \n",
      " 34  month            3591 non-null   int32         \n",
      " 35  quarter          3591 non-null   int32         \n",
      " 36  year             3591 non-null   int32         \n",
      " 37  is_month_start   3591 non-null   int64         \n",
      " 38  is_month_end     3591 non-null   int64         \n",
      " 39  is_quarter_end   3591 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(31), int32(4), int64(4)\n",
      "memory usage: 1.0 MB\n",
      "\n",
      "ğŸ“‚ CATEGORIZAÃ‡ÃƒO DE FEATURES:\n",
      "   ğŸ¢ OHLC/Volume (5): ['Ãšltimo', 'Abertura', 'MÃ¡xima', 'MÃ­nima', 'Volume']\n",
      "   ğŸ“… Temporais (8): ['Data', 'day_of_week', 'month', 'quarter', 'year', 'is_month_start', 'is_month_end', 'is_quarter_end']\n",
      "   ğŸ“ˆ TÃ©cnicas (16): ['MA_5', 'MA_10', 'MA_20', 'MA_50', 'BB_Upper']...\n",
      "   â° Shifted (0): []\n",
      "   ğŸ•¯ï¸ Candlestick (2): ['high_close_prev', 'low_close_prev']\n",
      "   ğŸ¯ Target (1): ['Target']\n",
      "   â“ Outras (8): ['Variacao', 'Signal_Line', 'true_range', 'returns', 'Price_Range']...\n",
      "\n",
      "ğŸš¨ ANÃLISE DE MUDANÃ‡AS:\n",
      "   ğŸ“‰ Features PERDIDAS (4):\n",
      "      âŒ BB_Middle\n",
      "      âŒ Var%\n",
      "      âŒ Vol.\n",
      "      âŒ high_low\n",
      "   ğŸ“ˆ Features GANHAS (0):\n",
      "      â– Nenhuma feature ganha\n",
      "   ğŸ“Š MudanÃ§a lÃ­quida: -4 features\n",
      "\n",
      "ğŸ” QUALIDADE DOS DADOS:\n",
      "   Colunas com valores ausentes: 19\n",
      "   Top 5 com mais NaNs:\n",
      "      MA_5: 4 (0.1%)\n",
      "      MA_10: 9 (0.3%)\n",
      "      MA_20: 19 (0.5%)\n",
      "      MA_50: 49 (1.4%)\n",
      "      BB_Upper: 19 (0.5%)\n",
      "\n",
      "âœ… Auditoria de STEP 04 - SeleÃ§Ã£o de Features concluÃ­da\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ RESUMO STEP 04:\n",
      "   âœ… Features selecionadas: 40\n",
      "   ğŸ“Š Features removidas: 4\n",
      "   ğŸ¯ Shape final: (3591, 40)\n"
     ]
    }
   ],
   "source": [
    "# STEP 04: SELEÃ‡ÃƒO DE FEATURES - PONTO CRÃTICO!\n",
    "print(\"\\nğŸ“‚ STEP 04: SeleÃ§Ã£o de features (PONTO CRÃTICO)...\")\n",
    "print(\"ğŸš¨ ATENÃ‡ÃƒO: Esta Ã© uma Ã¡rea comum para 'PENHASCOS' de features!\")\n",
    "\n",
    "# ANTES da seleÃ§Ã£o - checkpoint crÃ­tico\n",
    "print(f\"\\nğŸ” CHECKPOINT ANTES DA SELEÃ‡ÃƒO:\")\n",
    "print(f\"   Features disponÃ­veis: {df_step03_features.shape[1]}\")\n",
    "print(f\"   Primeiras 10: {list(df_step03_features.columns)[:10]}\")\n",
    "print(f\"   Ãšltimas 10: {list(df_step03_features.columns)[-10:]}\")\n",
    "\n",
    "# Criar cÃ³pia para seleÃ§Ã£o\n",
    "df_step04_selected = df_step03_features.copy()\n",
    "\n",
    "# ESTRATÃ‰GIA CONSERVADORA: Manter TODAS as features criadas\n",
    "# Apenas remover colunas auxiliares e duplicadas\n",
    "columns_to_remove = [\n",
    "    'Vol.',  # VersÃ£o string do volume\n",
    "    'Var%',  # VersÃ£o string da variaÃ§Ã£o\n",
    "    'high_low',  # Auxiliar para ATR\n",
    "    'BB_Middle'  # Duplicata da MA_20\n",
    "]\n",
    "\n",
    "# Remover apenas colunas auxiliares\n",
    "columns_to_remove_existing = [col for col in columns_to_remove if col in df_step04_selected.columns]\n",
    "if columns_to_remove_existing:\n",
    "    print(f\"\\nğŸ—‘ï¸ Removendo apenas colunas auxiliares: {columns_to_remove_existing}\")\n",
    "    df_step04_selected = df_step04_selected.drop(columns=columns_to_remove_existing)\n",
    "else:\n",
    "    print(f\"\\nâœ… Nenhuma coluna auxiliar para remover\")\n",
    "\n",
    "# CHECKPOINT CRÃTICO: Verificar se nÃ£o perdemos features importantes\n",
    "features_importantes = [\n",
    "    'Abertura', 'MÃ¡xima', 'MÃ­nima', 'Ãšltimo', 'Volume',\n",
    "    'MA_5', 'MA_10', 'MA_20', 'MA_50',\n",
    "    'BB_Upper', 'BB_Lower', 'BB_Width', 'BB_Position',\n",
    "    'RSI', 'MACD', 'Signal_Line',\n",
    "    'atr_5', 'atr_10', 'atr_20',\n",
    "    'volatility_5', 'volatility_10', 'volatility_20',\n",
    "    'Price_Range', 'Price_Position', 'Gap', 'hl_close_ratio',\n",
    "    'day_of_week', 'month', 'quarter', 'year',\n",
    "    'is_month_start', 'is_month_end', 'is_quarter_end',\n",
    "    'Target'\n",
    "]\n",
    "\n",
    "features_perdidas = [f for f in features_importantes if f not in df_step04_selected.columns]\n",
    "if features_perdidas:\n",
    "    print(f\"\\nğŸš¨ ALERTA: Features importantes perdidas: {features_perdidas}\")\n",
    "else:\n",
    "    print(f\"\\nâœ… Todas as features importantes preservadas\")\n",
    "\n",
    "# Auditoria da seleÃ§Ã£o\n",
    "audit_step04 = audit_pipeline_step(\n",
    "    df_step04_selected, \n",
    "    \"STEP 04 - SeleÃ§Ã£o de Features\", \n",
    "    expected_min_cols=len(features_importantes),\n",
    "    previous_df=df_step03_features\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“‹ RESUMO STEP 04:\")\n",
    "print(f\"   âœ… Features selecionadas: {df_step04_selected.shape[1]}\")\n",
    "print(f\"   ğŸ“Š Features removidas: {df_step03_features.shape[1] - df_step04_selected.shape[1]}\")\n",
    "print(f\"   ğŸ¯ Shape final: {df_step04_selected.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 05: CORREÃ‡ÃƒO TEMPORAL (PENHASCO CRÃTICO!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‚ STEP 05: CorreÃ§Ã£o temporal (PENHASCO CRÃTICO!)...\n",
      "ğŸš¨ ATENÃ‡ÃƒO: Esta Ã© a Ã¡rea mais provÃ¡vel para perda massiva de features!\n",
      "\n",
      "ğŸ” CHECKPOINT ANTES DA CORREÃ‡ÃƒO TEMPORAL:\n",
      "   Features disponÃ­veis: 40\n",
      "   Shape: (3591, 40)\n",
      "\n",
      "ğŸ“Š ANÃLISE DE FEATURES PARA SHIFT:\n",
      "   Features para shift: 31 de 31\n",
      "   Features sem shift: 9 de 9\n",
      "\n",
      "â° Aplicando shift temporal...\n",
      "\n",
      "ğŸ” CHECKPOINT APÃ“S CORREÃ‡ÃƒO TEMPORAL:\n",
      "   Features antes: 40\n",
      "   Features depois: 40\n",
      "   MudanÃ§a: +0\n",
      "\n",
      "ğŸ“Š VERIFICAÃ‡ÃƒO DE FEATURES SHIFTED:\n",
      "   Esperadas: 31\n",
      "   Criadas: 31\n",
      "   âœ… Todas as features shifted criadas corretamente\n",
      "\n",
      "============================================================\n",
      "ğŸ” AUDITORIA: STEP 05 - CORREÃ‡ÃƒO TEMPORAL\n",
      "============================================================\n",
      "ğŸ“Š INFORMAÃ‡Ã•ES BÃSICAS:\n",
      "   Shape: (3590, 40)\n",
      "   MemÃ³ria: 1.04 MB\n",
      "\n",
      "ğŸ“‹ DETALHES DAS COLUNAS (.info()):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3590 entries, 0 to 3589\n",
      "Data columns (total 40 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   Data                     3590 non-null   datetime64[ns]\n",
      " 1   day_of_week              3590 non-null   int32         \n",
      " 2   month                    3590 non-null   int32         \n",
      " 3   quarter                  3590 non-null   int32         \n",
      " 4   year                     3590 non-null   int32         \n",
      " 5   is_month_start           3590 non-null   int64         \n",
      " 6   is_month_end             3590 non-null   int64         \n",
      " 7   is_quarter_end           3590 non-null   int64         \n",
      " 8   Target                   3590 non-null   int64         \n",
      " 9   Abertura_shifted         3590 non-null   float64       \n",
      " 10  MÃ¡xima_shifted           3590 non-null   float64       \n",
      " 11  MÃ­nima_shifted           3590 non-null   float64       \n",
      " 12  Ãšltimo_shifted           3590 non-null   float64       \n",
      " 13  Volume_shifted           3590 non-null   float64       \n",
      " 14  MA_5_shifted             3586 non-null   float64       \n",
      " 15  MA_10_shifted            3581 non-null   float64       \n",
      " 16  MA_20_shifted            3571 non-null   float64       \n",
      " 17  MA_50_shifted            3541 non-null   float64       \n",
      " 18  BB_Upper_shifted         3571 non-null   float64       \n",
      " 19  BB_Lower_shifted         3571 non-null   float64       \n",
      " 20  BB_Width_shifted         3571 non-null   float64       \n",
      " 21  BB_Position_shifted      3571 non-null   float64       \n",
      " 22  RSI_shifted              3577 non-null   float64       \n",
      " 23  MACD_shifted             3590 non-null   float64       \n",
      " 24  Signal_Line_shifted      3590 non-null   float64       \n",
      " 25  atr_5_shifted            3586 non-null   float64       \n",
      " 26  atr_10_shifted           3581 non-null   float64       \n",
      " 27  atr_20_shifted           3571 non-null   float64       \n",
      " 28  volatility_5_shifted     3585 non-null   float64       \n",
      " 29  volatility_10_shifted    3580 non-null   float64       \n",
      " 30  volatility_20_shifted    3570 non-null   float64       \n",
      " 31  Price_Range_shifted      3590 non-null   float64       \n",
      " 32  Price_Position_shifted   3590 non-null   float64       \n",
      " 33  Gap_shifted              3589 non-null   float64       \n",
      " 34  hl_close_ratio_shifted   3590 non-null   float64       \n",
      " 35  true_range_shifted       3590 non-null   float64       \n",
      " 36  high_close_prev_shifted  3589 non-null   float64       \n",
      " 37  low_close_prev_shifted   3589 non-null   float64       \n",
      " 38  returns_shifted          3589 non-null   float64       \n",
      " 39  Variacao_shifted         3590 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(31), int32(4), int64(4)\n",
      "memory usage: 1.0 MB\n",
      "\n",
      "ğŸ“‚ CATEGORIZAÃ‡ÃƒO DE FEATURES:\n",
      "   ğŸ¢ OHLC/Volume (0): []\n",
      "   ğŸ“… Temporais (8): ['Data', 'day_of_week', 'month', 'quarter', 'year', 'is_month_start', 'is_month_end', 'is_quarter_end']\n",
      "   ğŸ“ˆ TÃ©cnicas (18): ['MÃ¡xima_shifted', 'MÃ­nima_shifted', 'MA_5_shifted', 'MA_10_shifted', 'MA_20_shifted']...\n",
      "   â° Shifted (31): ['Abertura_shifted', 'MÃ¡xima_shifted', 'MÃ­nima_shifted', 'Ãšltimo_shifted', 'Volume_shifted']...\n",
      "   ğŸ•¯ï¸ Candlestick (2): ['high_close_prev_shifted', 'low_close_prev_shifted']\n",
      "   ğŸ¯ Target (1): ['Target']\n",
      "   â“ Outras (0): []\n",
      "\n",
      "ğŸš¨ ANÃLISE DE MUDANÃ‡AS:\n",
      "   ğŸ“‰ Features PERDIDAS (31):\n",
      "      âŒ Abertura\n",
      "      âŒ BB_Lower\n",
      "      âŒ BB_Position\n",
      "      âŒ BB_Upper\n",
      "      âŒ BB_Width\n",
      "      âŒ Gap\n",
      "      âŒ MACD\n",
      "      âŒ MA_10\n",
      "      âŒ MA_20\n",
      "      âŒ MA_5\n",
      "      âŒ MA_50\n",
      "      âŒ MÃ¡xima\n",
      "      âŒ MÃ­nima\n",
      "      âŒ Price_Position\n",
      "      âŒ Price_Range\n",
      "      âŒ RSI\n",
      "      âŒ Signal_Line\n",
      "      âŒ Variacao\n",
      "      âŒ Volume\n",
      "      âŒ atr_10\n",
      "      âŒ atr_20\n",
      "      âŒ atr_5\n",
      "      âŒ high_close_prev\n",
      "      âŒ hl_close_ratio\n",
      "      âŒ low_close_prev\n",
      "      âŒ returns\n",
      "      âŒ true_range\n",
      "      âŒ volatility_10\n",
      "      âŒ volatility_20\n",
      "      âŒ volatility_5\n",
      "      âŒ Ãšltimo\n",
      "   ğŸ“ˆ Features GANHAS (31):\n",
      "      âœ… Abertura_shifted\n",
      "      âœ… BB_Lower_shifted\n",
      "      âœ… BB_Position_shifted\n",
      "      âœ… BB_Upper_shifted\n",
      "      âœ… BB_Width_shifted\n",
      "      âœ… Gap_shifted\n",
      "      âœ… MACD_shifted\n",
      "      âœ… MA_10_shifted\n",
      "      âœ… MA_20_shifted\n",
      "      âœ… MA_50_shifted\n",
      "      âœ… MA_5_shifted\n",
      "      âœ… MÃ¡xima_shifted\n",
      "      âœ… MÃ­nima_shifted\n",
      "      âœ… Price_Position_shifted\n",
      "      âœ… Price_Range_shifted\n",
      "      âœ… RSI_shifted\n",
      "      âœ… Signal_Line_shifted\n",
      "      âœ… Variacao_shifted\n",
      "      âœ… Volume_shifted\n",
      "      âœ… atr_10_shifted\n",
      "      âœ… atr_20_shifted\n",
      "      âœ… atr_5_shifted\n",
      "      âœ… high_close_prev_shifted\n",
      "      âœ… hl_close_ratio_shifted\n",
      "      âœ… low_close_prev_shifted\n",
      "      âœ… returns_shifted\n",
      "      âœ… true_range_shifted\n",
      "      âœ… volatility_10_shifted\n",
      "      âœ… volatility_20_shifted\n",
      "      âœ… volatility_5_shifted\n",
      "      âœ… Ãšltimo_shifted\n",
      "   ğŸ“Š MudanÃ§a lÃ­quida: +0 features\n",
      "\n",
      "ğŸš¨ ALERTA: PERDA SIGNIFICATIVA DE FEATURES!\n",
      "   31 features foram perdidas nesta etapa\n",
      "   Isso pode indicar um 'PENHASCO' no pipeline\n",
      "\n",
      "ğŸ” QUALIDADE DOS DADOS:\n",
      "   Colunas com valores ausentes: 19\n",
      "   Top 5 com mais NaNs:\n",
      "      MA_5_shifted: 4 (0.1%)\n",
      "      MA_10_shifted: 9 (0.3%)\n",
      "      MA_20_shifted: 19 (0.5%)\n",
      "      MA_50_shifted: 49 (1.4%)\n",
      "      BB_Upper_shifted: 19 (0.5%)\n",
      "\n",
      "âœ… Auditoria de STEP 05 - CorreÃ§Ã£o Temporal concluÃ­da\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ RESUMO STEP 05:\n",
      "   âœ… CorreÃ§Ã£o temporal aplicada\n",
      "   ğŸ“Š Features shifted criadas: 31\n",
      "   ğŸ¯ Shape final: (3590, 40)\n"
     ]
    }
   ],
   "source": [
    "# STEP 05: CORREÃ‡ÃƒO TEMPORAL - PENHASCO CRÃTICO!\n",
    "print(\"\\nğŸ“‚ STEP 05: CorreÃ§Ã£o temporal (PENHASCO CRÃTICO!)...\")\n",
    "print(\"ğŸš¨ ATENÃ‡ÃƒO: Esta Ã© a Ã¡rea mais provÃ¡vel para perda massiva de features!\")\n",
    "\n",
    "# CHECKPOINT ANTES DA CORREÃ‡ÃƒO TEMPORAL\n",
    "print(f\"\\nğŸ” CHECKPOINT ANTES DA CORREÃ‡ÃƒO TEMPORAL:\")\n",
    "print(f\"   Features disponÃ­veis: {df_step04_selected.shape[1]}\")\n",
    "print(f\"   Shape: {df_step04_selected.shape}\")\n",
    "\n",
    "# Criar cÃ³pia para correÃ§Ã£o temporal\n",
    "df_step05_temporal = df_step04_selected.copy()\n",
    "\n",
    "# ESTRATÃ‰GIA CONSERVADORA: Aplicar shift apenas onde necessÃ¡rio\n",
    "# Identificar features que precisam de shift (dados do presente/futuro)\n",
    "features_to_shift = [\n",
    "    'Abertura', 'MÃ¡xima', 'MÃ­nima', 'Ãšltimo', 'Volume',\n",
    "    'MA_5', 'MA_10', 'MA_20', 'MA_50',\n",
    "    'BB_Upper', 'BB_Lower', 'BB_Width', 'BB_Position',\n",
    "    'RSI', 'MACD', 'Signal_Line',\n",
    "    'atr_5', 'atr_10', 'atr_20',\n",
    "    'volatility_5', 'volatility_10', 'volatility_20',\n",
    "    'Price_Range', 'Price_Position', 'Gap', 'hl_close_ratio',\n",
    "    'true_range', 'high_close_prev', 'low_close_prev',\n",
    "    'returns', 'Variacao'\n",
    "]\n",
    "\n",
    "# Features que NÃƒO precisam de shift (dados temporais do passado)\n",
    "features_no_shift = [\n",
    "    'Data', 'day_of_week', 'month', 'quarter', 'year',\n",
    "    'is_month_start', 'is_month_end', 'is_quarter_end',\n",
    "    'Target'\n",
    "]\n",
    "\n",
    "# Verificar quais features estÃ£o disponÃ­veis\n",
    "available_to_shift = [f for f in features_to_shift if f in df_step05_temporal.columns]\n",
    "available_no_shift = [f for f in features_no_shift if f in df_step05_temporal.columns]\n",
    "\n",
    "print(f\"\\nğŸ“Š ANÃLISE DE FEATURES PARA SHIFT:\")\n",
    "print(f\"   Features para shift: {len(available_to_shift)} de {len(features_to_shift)}\")\n",
    "print(f\"   Features sem shift: {len(available_no_shift)} de {len(features_no_shift)}\")\n",
    "\n",
    "missing_to_shift = [f for f in features_to_shift if f not in df_step05_temporal.columns]\n",
    "if missing_to_shift:\n",
    "    print(f\"   âš ï¸ Features ausentes para shift: {missing_to_shift}\")\n",
    "\n",
    "# APLICAR SHIFT DE FORMA CONSERVADORA\n",
    "print(f\"\\nâ° Aplicando shift temporal...\")\n",
    "\n",
    "# Criar dataset final com features shifted\n",
    "df_temporal_final = pd.DataFrame()\n",
    "\n",
    "# 1. Manter features temporais sem shift\n",
    "for feature in available_no_shift:\n",
    "    df_temporal_final[feature] = df_step05_temporal[feature]\n",
    "\n",
    "# 2. Aplicar shift nas features de preÃ§o/indicadores\n",
    "for feature in available_to_shift:\n",
    "    df_temporal_final[f'{feature}_shifted'] = df_step05_temporal[feature].shift(1)\n",
    "\n",
    "# 3. Remover primeira linha (NaN devido ao shift)\n",
    "df_temporal_final = df_temporal_final.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "# CHECKPOINT CRÃTICO APÃ“S CORREÃ‡ÃƒO TEMPORAL\n",
    "print(f\"\\nğŸ” CHECKPOINT APÃ“S CORREÃ‡ÃƒO TEMPORAL:\")\n",
    "print(f\"   Features antes: {df_step05_temporal.shape[1]}\")\n",
    "print(f\"   Features depois: {df_temporal_final.shape[1]}\")\n",
    "print(f\"   MudanÃ§a: {df_temporal_final.shape[1] - df_step05_temporal.shape[1]:+d}\")\n",
    "\n",
    "# Verificar se temos as features shifted esperadas\n",
    "expected_shifted = [f'{f}_shifted' for f in available_to_shift]\n",
    "actual_shifted = [col for col in df_temporal_final.columns if col.endswith('_shifted')]\n",
    "\n",
    "print(f\"\\nğŸ“Š VERIFICAÃ‡ÃƒO DE FEATURES SHIFTED:\")\n",
    "print(f\"   Esperadas: {len(expected_shifted)}\")\n",
    "print(f\"   Criadas: {len(actual_shifted)}\")\n",
    "\n",
    "missing_shifted = [f for f in expected_shifted if f not in df_temporal_final.columns]\n",
    "if missing_shifted:\n",
    "    print(f\"   âŒ Features shifted ausentes: {missing_shifted[:5]}{'...' if len(missing_shifted) > 5 else ''}\")\n",
    "else:\n",
    "    print(f\"   âœ… Todas as features shifted criadas corretamente\")\n",
    "\n",
    "# Atualizar variÃ¡vel para prÃ³xima etapa\n",
    "df_step05_temporal = df_temporal_final.copy()\n",
    "\n",
    "# Auditoria da correÃ§Ã£o temporal\n",
    "audit_step05 = audit_pipeline_step(\n",
    "    df_step05_temporal, \n",
    "    \"STEP 05 - CorreÃ§Ã£o Temporal\", \n",
    "    expected_min_cols=len(available_no_shift) + len(available_to_shift),\n",
    "    previous_df=df_step04_selected\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“‹ RESUMO STEP 05:\")\n",
    "print(f\"   âœ… CorreÃ§Ã£o temporal aplicada\")\n",
    "print(f\"   ğŸ“Š Features shifted criadas: {len(actual_shifted)}\")\n",
    "print(f\"   ğŸ¯ Shape final: {df_step05_temporal.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 06: PADRÃ•ES DE CANDLESTICK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‚ STEP 06: Criando padrÃµes de candlestick...\n",
      "\n",
      "ğŸ•¯ï¸ VERIFICAÃ‡ÃƒO DE COLUNAS OHLC SHIFTED:\n",
      "   NecessÃ¡rias: ['Abertura_shifted', 'MÃ¡xima_shifted', 'MÃ­nima_shifted', 'Ãšltimo_shifted']\n",
      "   DisponÃ­veis: ['Abertura_shifted', 'MÃ¡xima_shifted', 'MÃ­nima_shifted', 'Ãšltimo_shifted']\n",
      "   âœ… Todas as colunas OHLC shifted disponÃ­veis\n",
      "\n",
      "ğŸ“Š Criando padrÃµes de candlestick...\n",
      "   âœ… 9 features de candlestick criadas\n",
      "\n",
      "============================================================\n",
      "ğŸ” AUDITORIA: STEP 06 - PADRÃ•ES DE CANDLESTICK\n",
      "============================================================\n",
      "ğŸ“Š INFORMAÃ‡Ã•ES BÃSICAS:\n",
      "   Shape: (3590, 49)\n",
      "   MemÃ³ria: 1.29 MB\n",
      "\n",
      "ğŸ“‹ DETALHES DAS COLUNAS (.info()):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3590 entries, 0 to 3589\n",
      "Data columns (total 49 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   Data                     3590 non-null   datetime64[ns]\n",
      " 1   day_of_week              3590 non-null   int32         \n",
      " 2   month                    3590 non-null   int32         \n",
      " 3   quarter                  3590 non-null   int32         \n",
      " 4   year                     3590 non-null   int32         \n",
      " 5   is_month_start           3590 non-null   int64         \n",
      " 6   is_month_end             3590 non-null   int64         \n",
      " 7   is_quarter_end           3590 non-null   int64         \n",
      " 8   Target                   3590 non-null   int64         \n",
      " 9   Abertura_shifted         3590 non-null   float64       \n",
      " 10  MÃ¡xima_shifted           3590 non-null   float64       \n",
      " 11  MÃ­nima_shifted           3590 non-null   float64       \n",
      " 12  Ãšltimo_shifted           3590 non-null   float64       \n",
      " 13  Volume_shifted           3590 non-null   float64       \n",
      " 14  MA_5_shifted             3586 non-null   float64       \n",
      " 15  MA_10_shifted            3581 non-null   float64       \n",
      " 16  MA_20_shifted            3571 non-null   float64       \n",
      " 17  MA_50_shifted            3541 non-null   float64       \n",
      " 18  BB_Upper_shifted         3571 non-null   float64       \n",
      " 19  BB_Lower_shifted         3571 non-null   float64       \n",
      " 20  BB_Width_shifted         3571 non-null   float64       \n",
      " 21  BB_Position_shifted      3571 non-null   float64       \n",
      " 22  RSI_shifted              3577 non-null   float64       \n",
      " 23  MACD_shifted             3590 non-null   float64       \n",
      " 24  Signal_Line_shifted      3590 non-null   float64       \n",
      " 25  atr_5_shifted            3586 non-null   float64       \n",
      " 26  atr_10_shifted           3581 non-null   float64       \n",
      " 27  atr_20_shifted           3571 non-null   float64       \n",
      " 28  volatility_5_shifted     3585 non-null   float64       \n",
      " 29  volatility_10_shifted    3580 non-null   float64       \n",
      " 30  volatility_20_shifted    3570 non-null   float64       \n",
      " 31  Price_Range_shifted      3590 non-null   float64       \n",
      " 32  Price_Position_shifted   3590 non-null   float64       \n",
      " 33  Gap_shifted              3589 non-null   float64       \n",
      " 34  hl_close_ratio_shifted   3590 non-null   float64       \n",
      " 35  true_range_shifted       3590 non-null   float64       \n",
      " 36  high_close_prev_shifted  3589 non-null   float64       \n",
      " 37  low_close_prev_shifted   3589 non-null   float64       \n",
      " 38  returns_shifted          3589 non-null   float64       \n",
      " 39  Variacao_shifted         3590 non-null   float64       \n",
      " 40  doji_prev                3590 non-null   int64         \n",
      " 41  hammer_prev              3590 non-null   int64         \n",
      " 42  shooting_star_prev       3590 non-null   int64         \n",
      " 43  engulfing_bullish_prev   3590 non-null   int64         \n",
      " 44  bullish_candle_prev      3590 non-null   int64         \n",
      " 45  bearish_candle_prev      3590 non-null   int64         \n",
      " 46  body_size_prev           3590 non-null   float64       \n",
      " 47  upper_shadow_prev        3590 non-null   float64       \n",
      " 48  lower_shadow_prev        3590 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(34), int32(4), int64(10)\n",
      "memory usage: 1.3 MB\n",
      "\n",
      "ğŸ“‚ CATEGORIZAÃ‡ÃƒO DE FEATURES:\n",
      "   ğŸ¢ OHLC/Volume (0): []\n",
      "   ğŸ“… Temporais (8): ['Data', 'day_of_week', 'month', 'quarter', 'year', 'is_month_start', 'is_month_end', 'is_quarter_end']\n",
      "   ğŸ“ˆ TÃ©cnicas (18): ['MÃ¡xima_shifted', 'MÃ­nima_shifted', 'MA_5_shifted', 'MA_10_shifted', 'MA_20_shifted']...\n",
      "   â° Shifted (31): ['Abertura_shifted', 'MÃ¡xima_shifted', 'MÃ­nima_shifted', 'Ãšltimo_shifted', 'Volume_shifted']...\n",
      "   ğŸ•¯ï¸ Candlestick (11): ['high_close_prev_shifted', 'low_close_prev_shifted', 'doji_prev', 'hammer_prev', 'shooting_star_prev']...\n",
      "   ğŸ¯ Target (1): ['Target']\n",
      "   â“ Outras (0): []\n",
      "\n",
      "ğŸš¨ ANÃLISE DE MUDANÃ‡AS:\n",
      "   ğŸ“‰ Features PERDIDAS (0):\n",
      "      âœ… Nenhuma feature perdida\n",
      "   ğŸ“ˆ Features GANHAS (9):\n",
      "      âœ… bearish_candle_prev\n",
      "      âœ… body_size_prev\n",
      "      âœ… bullish_candle_prev\n",
      "      âœ… doji_prev\n",
      "      âœ… engulfing_bullish_prev\n",
      "      âœ… hammer_prev\n",
      "      âœ… lower_shadow_prev\n",
      "      âœ… shooting_star_prev\n",
      "      âœ… upper_shadow_prev\n",
      "   ğŸ“Š MudanÃ§a lÃ­quida: +9 features\n",
      "\n",
      "ğŸ” QUALIDADE DOS DADOS:\n",
      "   Colunas com valores ausentes: 19\n",
      "   Top 5 com mais NaNs:\n",
      "      MA_5_shifted: 4 (0.1%)\n",
      "      MA_10_shifted: 9 (0.3%)\n",
      "      MA_20_shifted: 19 (0.5%)\n",
      "      MA_50_shifted: 49 (1.4%)\n",
      "      BB_Upper_shifted: 19 (0.5%)\n",
      "\n",
      "âœ… Auditoria de STEP 06 - PadrÃµes de Candlestick concluÃ­da\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ RESUMO STEP 06:\n",
      "   âœ… Features de candlestick criadas: 9\n",
      "   ğŸ“Š Total de features: 49\n",
      "   ğŸ¯ Shape final: (3590, 49)\n"
     ]
    }
   ],
   "source": [
    "# STEP 06: PADRÃ•ES DE CANDLESTICK\n",
    "print(\"\\nğŸ“‚ STEP 06: Criando padrÃµes de candlestick...\")\n",
    "\n",
    "# Criar cÃ³pia para candlestick\n",
    "df_step06_candlestick = df_step05_temporal.copy()\n",
    "\n",
    "# Verificar se temos as colunas OHLC shifted necessÃ¡rias\n",
    "ohlc_shifted_cols = ['Abertura_shifted', 'MÃ¡xima_shifted', 'MÃ­nima_shifted', 'Ãšltimo_shifted']\n",
    "available_ohlc_shifted = [col for col in ohlc_shifted_cols if col in df_step06_candlestick.columns]\n",
    "\n",
    "print(f\"\\nğŸ•¯ï¸ VERIFICAÃ‡ÃƒO DE COLUNAS OHLC SHIFTED:\")\n",
    "print(f\"   NecessÃ¡rias: {ohlc_shifted_cols}\")\n",
    "print(f\"   DisponÃ­veis: {available_ohlc_shifted}\")\n",
    "\n",
    "if len(available_ohlc_shifted) == 4:\n",
    "    print(f\"   âœ… Todas as colunas OHLC shifted disponÃ­veis\")\n",
    "    \n",
    "    # Renomear temporariamente para facilitar cÃ¡lculos\n",
    "    ohlc_temp = df_step06_candlestick[available_ohlc_shifted].copy()\n",
    "    ohlc_temp.columns = ['Open', 'High', 'Low', 'Close']\n",
    "    \n",
    "    # FunÃ§Ãµes de padrÃµes de candlestick\n",
    "    def detect_doji(df, threshold=0.1):\n",
    "        body_size = abs(df['Close'] - df['Open'])\n",
    "        total_range = df['High'] - df['Low']\n",
    "        return (body_size / total_range < threshold).astype(int)\n",
    "    \n",
    "    def detect_hammer(df):\n",
    "        body_size = abs(df['Close'] - df['Open'])\n",
    "        lower_shadow = df[['Open', 'Close']].min(axis=1) - df['Low']\n",
    "        upper_shadow = df['High'] - df[['Open', 'Close']].max(axis=1)\n",
    "        return ((lower_shadow > 2 * body_size) & (upper_shadow < body_size)).astype(int)\n",
    "    \n",
    "    def detect_shooting_star(df):\n",
    "        body_size = abs(df['Close'] - df['Open'])\n",
    "        lower_shadow = df[['Open', 'Close']].min(axis=1) - df['Low']\n",
    "        upper_shadow = df['High'] - df[['Open', 'Close']].max(axis=1)\n",
    "        return ((upper_shadow > 2 * body_size) & (lower_shadow < body_size)).astype(int)\n",
    "    \n",
    "    def detect_engulfing_bullish(df):\n",
    "        current_bullish = df['Close'] > df['Open']\n",
    "        prev_bearish = (df['Close'].shift(1) < df['Open'].shift(1))\n",
    "        current_open_below_prev_close = df['Open'] < df['Close'].shift(1)\n",
    "        current_close_above_prev_open = df['Close'] > df['Open'].shift(1)\n",
    "        return (current_bullish & prev_bearish & current_open_below_prev_close & current_close_above_prev_open).astype(int)\n",
    "    \n",
    "    # Aplicar padrÃµes\n",
    "    print(f\"\\nğŸ“Š Criando padrÃµes de candlestick...\")\n",
    "    \n",
    "    df_step06_candlestick['doji_prev'] = detect_doji(ohlc_temp)\n",
    "    df_step06_candlestick['hammer_prev'] = detect_hammer(ohlc_temp)\n",
    "    df_step06_candlestick['shooting_star_prev'] = detect_shooting_star(ohlc_temp)\n",
    "    df_step06_candlestick['engulfing_bullish_prev'] = detect_engulfing_bullish(ohlc_temp)\n",
    "    \n",
    "    # PadrÃµes adicionais\n",
    "    df_step06_candlestick['bullish_candle_prev'] = (ohlc_temp['Close'] > ohlc_temp['Open']).astype(int)\n",
    "    df_step06_candlestick['bearish_candle_prev'] = (ohlc_temp['Close'] < ohlc_temp['Open']).astype(int)\n",
    "    \n",
    "    # MÃ©tricas de candlestick\n",
    "    df_step06_candlestick['body_size_prev'] = abs(ohlc_temp['Close'] - ohlc_temp['Open'])\n",
    "    df_step06_candlestick['upper_shadow_prev'] = ohlc_temp['High'] - ohlc_temp[['Open', 'Close']].max(axis=1)\n",
    "    df_step06_candlestick['lower_shadow_prev'] = ohlc_temp[['Open', 'Close']].min(axis=1) - ohlc_temp['Low']\n",
    "    \n",
    "    candlestick_features_created = 9\n",
    "    print(f\"   âœ… {candlestick_features_created} features de candlestick criadas\")\n",
    "    \n",
    "else:\n",
    "    print(f\"   âŒ Colunas OHLC shifted insuficientes\")\n",
    "    print(f\"   Ausentes: {[col for col in ohlc_shifted_cols if col not in df_step06_candlestick.columns]}\")\n",
    "    candlestick_features_created = 0\n",
    "\n",
    "# Auditoria dos padrÃµes de candlestick\n",
    "audit_step06 = audit_pipeline_step(\n",
    "    df_step06_candlestick, \n",
    "    \"STEP 06 - PadrÃµes de Candlestick\", \n",
    "    expected_min_cols=df_step05_temporal.shape[1] + candlestick_features_created,\n",
    "    previous_df=df_step05_temporal\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“‹ RESUMO STEP 06:\")\n",
    "print(f\"   âœ… Features de candlestick criadas: {candlestick_features_created}\")\n",
    "print(f\"   ğŸ“Š Total de features: {df_step06_candlestick.shape[1]}\")\n",
    "print(f\"   ğŸ¯ Shape final: {df_step06_candlestick.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 07: DATASET FINAL E AUDITORIA COMPLETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‚ STEP 07: Preparando dataset final...\n",
      "\n",
      "ğŸ§¹ Limpeza final de dados...\n",
      "   Shape antes da limpeza: (3590, 49)\n",
      "   Shape apÃ³s limpeza: (3586, 49)\n",
      "   Linhas removidas: 4\n",
      "\n",
      "============================================================\n",
      "ğŸ” AUDITORIA: STEP 07 - DATASET FINAL\n",
      "============================================================\n",
      "ğŸ“Š INFORMAÃ‡Ã•ES BÃSICAS:\n",
      "   Shape: (3586, 49)\n",
      "   MemÃ³ria: 1.31 MB\n",
      "\n",
      "ğŸ“‹ DETALHES DAS COLUNAS (.info()):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3586 entries, 4 to 3589\n",
      "Data columns (total 49 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   Data                     3586 non-null   datetime64[ns]\n",
      " 1   day_of_week              3586 non-null   int32         \n",
      " 2   month                    3586 non-null   int32         \n",
      " 3   quarter                  3586 non-null   int32         \n",
      " 4   year                     3586 non-null   int32         \n",
      " 5   is_month_start           3586 non-null   int64         \n",
      " 6   is_month_end             3586 non-null   int64         \n",
      " 7   is_quarter_end           3586 non-null   int64         \n",
      " 8   Target                   3586 non-null   int64         \n",
      " 9   Abertura_shifted         3586 non-null   float64       \n",
      " 10  MÃ¡xima_shifted           3586 non-null   float64       \n",
      " 11  MÃ­nima_shifted           3586 non-null   float64       \n",
      " 12  Ãšltimo_shifted           3586 non-null   float64       \n",
      " 13  Volume_shifted           3586 non-null   float64       \n",
      " 14  MA_5_shifted             3586 non-null   float64       \n",
      " 15  MA_10_shifted            3581 non-null   float64       \n",
      " 16  MA_20_shifted            3571 non-null   float64       \n",
      " 17  MA_50_shifted            3541 non-null   float64       \n",
      " 18  BB_Upper_shifted         3571 non-null   float64       \n",
      " 19  BB_Lower_shifted         3571 non-null   float64       \n",
      " 20  BB_Width_shifted         3571 non-null   float64       \n",
      " 21  BB_Position_shifted      3571 non-null   float64       \n",
      " 22  RSI_shifted              3577 non-null   float64       \n",
      " 23  MACD_shifted             3586 non-null   float64       \n",
      " 24  Signal_Line_shifted      3586 non-null   float64       \n",
      " 25  atr_5_shifted            3586 non-null   float64       \n",
      " 26  atr_10_shifted           3581 non-null   float64       \n",
      " 27  atr_20_shifted           3571 non-null   float64       \n",
      " 28  volatility_5_shifted     3585 non-null   float64       \n",
      " 29  volatility_10_shifted    3580 non-null   float64       \n",
      " 30  volatility_20_shifted    3570 non-null   float64       \n",
      " 31  Price_Range_shifted      3586 non-null   float64       \n",
      " 32  Price_Position_shifted   3586 non-null   float64       \n",
      " 33  Gap_shifted              3586 non-null   float64       \n",
      " 34  hl_close_ratio_shifted   3586 non-null   float64       \n",
      " 35  true_range_shifted       3586 non-null   float64       \n",
      " 36  high_close_prev_shifted  3586 non-null   float64       \n",
      " 37  low_close_prev_shifted   3586 non-null   float64       \n",
      " 38  returns_shifted          3586 non-null   float64       \n",
      " 39  Variacao_shifted         3586 non-null   float64       \n",
      " 40  doji_prev                3586 non-null   int64         \n",
      " 41  hammer_prev              3586 non-null   int64         \n",
      " 42  shooting_star_prev       3586 non-null   int64         \n",
      " 43  engulfing_bullish_prev   3586 non-null   int64         \n",
      " 44  bullish_candle_prev      3586 non-null   int64         \n",
      " 45  bearish_candle_prev      3586 non-null   int64         \n",
      " 46  body_size_prev           3586 non-null   float64       \n",
      " 47  upper_shadow_prev        3586 non-null   float64       \n",
      " 48  lower_shadow_prev        3586 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(34), int32(4), int64(10)\n",
      "memory usage: 1.3 MB\n",
      "\n",
      "ğŸ“‚ CATEGORIZAÃ‡ÃƒO DE FEATURES:\n",
      "   ğŸ¢ OHLC/Volume (0): []\n",
      "   ğŸ“… Temporais (8): ['Data', 'day_of_week', 'month', 'quarter', 'year', 'is_month_start', 'is_month_end', 'is_quarter_end']\n",
      "   ğŸ“ˆ TÃ©cnicas (18): ['MÃ¡xima_shifted', 'MÃ­nima_shifted', 'MA_5_shifted', 'MA_10_shifted', 'MA_20_shifted']...\n",
      "   â° Shifted (31): ['Abertura_shifted', 'MÃ¡xima_shifted', 'MÃ­nima_shifted', 'Ãšltimo_shifted', 'Volume_shifted']...\n",
      "   ğŸ•¯ï¸ Candlestick (11): ['high_close_prev_shifted', 'low_close_prev_shifted', 'doji_prev', 'hammer_prev', 'shooting_star_prev']...\n",
      "   ğŸ¯ Target (1): ['Target']\n",
      "   â“ Outras (0): []\n",
      "\n",
      "ğŸš¨ ANÃLISE DE MUDANÃ‡AS:\n",
      "   ğŸ“‰ Features PERDIDAS (0):\n",
      "      âœ… Nenhuma feature perdida\n",
      "   ğŸ“ˆ Features GANHAS (0):\n",
      "      â– Nenhuma feature ganha\n",
      "   ğŸ“Š MudanÃ§a lÃ­quida: +0 features\n",
      "\n",
      "âš ï¸ AVISO: Menos colunas que esperado\n",
      "   Esperado: >= 50\n",
      "   Atual: 49\n",
      "\n",
      "ğŸ” QUALIDADE DOS DADOS:\n",
      "   Colunas com valores ausentes: 13\n",
      "   Top 5 com mais NaNs:\n",
      "      MA_10_shifted: 5 (0.1%)\n",
      "      MA_20_shifted: 15 (0.4%)\n",
      "      MA_50_shifted: 45 (1.3%)\n",
      "      BB_Upper_shifted: 15 (0.4%)\n",
      "      BB_Lower_shifted: 15 (0.4%)\n",
      "\n",
      "âœ… Auditoria de STEP 07 - Dataset Final concluÃ­da\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ RESUMO STEP 07:\n",
      "   âœ… Dataset final preparado\n",
      "   ğŸ“Š Features finais: 49\n",
      "   ğŸ¯ Shape final: (3586, 49)\n",
      "   ğŸ’¾ Pronto para modelagem!\n"
     ]
    }
   ],
   "source": [
    "# STEP 07: DATASET FINAL E AUDITORIA COMPLETA\n",
    "print(\"\\nğŸ“‚ STEP 07: Preparando dataset final...\")\n",
    "\n",
    "# Criar dataset final\n",
    "df_step07_final = df_step06_candlestick.copy()\n",
    "\n",
    "# Limpeza final - remover linhas com muitos NaN\n",
    "print(f\"\\nğŸ§¹ Limpeza final de dados...\")\n",
    "print(f\"   Shape antes da limpeza: {df_step07_final.shape}\")\n",
    "\n",
    "# Contar NaN por linha\n",
    "nan_counts = df_step07_final.isnull().sum(axis=1)\n",
    "threshold = df_step07_final.shape[1] * 0.3  # Remover linhas com mais de 30% de NaN\n",
    "\n",
    "df_step07_final = df_step07_final[nan_counts <= threshold]\n",
    "print(f\"   Shape apÃ³s limpeza: {df_step07_final.shape}\")\n",
    "print(f\"   Linhas removidas: {df_step06_candlestick.shape[0] - df_step07_final.shape[0]}\")\n",
    "\n",
    "# Auditoria final\n",
    "audit_step07 = audit_pipeline_step(\n",
    "    df_step07_final, \n",
    "    \"STEP 07 - Dataset Final\", \n",
    "    expected_min_cols=50,  # Esperamos pelo menos 50 features\n",
    "    previous_df=df_step06_candlestick\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“‹ RESUMO STEP 07:\")\n",
    "print(f\"   âœ… Dataset final preparado\")\n",
    "print(f\"   ğŸ“Š Features finais: {df_step07_final.shape[1]}\")\n",
    "print(f\"   ğŸ¯ Shape final: {df_step07_final.shape}\")\n",
    "print(f\"   ğŸ’¾ Pronto para modelagem!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUDITORIA COMPLETA DO PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” AUDITORIA COMPLETA DO PIPELINE EXPLÃCITO\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š RESUMO COMPLETO DO PIPELINE:\n",
      "Step                      Shape           Features   TÃ©cnicas   Shifted    Candlestick \n",
      "-------------------------------------------------------------------------------------\n",
      "STEP 01 - Dados Brutos    3592x7          7          0          0          0           \n",
      "STEP 02 - Processamento... 3591x10         10         0          0          0           \n",
      "STEP 03 - Features TÃ©cn... 3591x44         44         17         0          2           \n",
      "STEP 04 - SeleÃ§Ã£o de Fe... 3591x40         40         16         0          2           \n",
      "STEP 05 - CorreÃ§Ã£o Temp... 3590x40         40         18         31         2           \n",
      "STEP 06 - PadrÃµes de Ca... 3590x49         49         18         31         11          \n",
      "STEP 07 - Dataset Final   3586x49         49         18         31         11          \n",
      "\n",
      "ğŸ“ˆ EVOLUÃ‡ÃƒO DAS FEATURES:\n",
      "   STEP 01 - Dados Brutos â†’ STEP 02 - Processamento BÃ¡sico: +3 features\n",
      "   STEP 02 - Processamento BÃ¡sico â†’ STEP 03 - Features TÃ©cnicas: +34 features\n",
      "   STEP 03 - Features TÃ©cnicas â†’ STEP 04 - SeleÃ§Ã£o de Features: -4 features\n",
      "   STEP 04 - SeleÃ§Ã£o de Features â†’ STEP 05 - CorreÃ§Ã£o Temporal: 0 features\n",
      "   STEP 05 - CorreÃ§Ã£o Temporal â†’ STEP 06 - PadrÃµes de Candlestick: +9 features\n",
      "   STEP 06 - PadrÃµes de Candlestick â†’ STEP 07 - Dataset Final: 0 features\n",
      "\n",
      "ğŸš¨ IDENTIFICAÃ‡ÃƒO DE PENHASCOS:\n",
      "   âœ… Nenhum penhasco significativo identificado\n",
      "\n",
      "âœ… VERIFICAÃ‡ÃƒO FINAL:\n",
      "   Dataset inicial: (3592, 7)\n",
      "   Dataset final: (3586, 49)\n",
      "   Features criadas: +42\n",
      "   Linhas preservadas: 99.8%\n",
      "\n",
      "ğŸ¯ STATUS DO PIPELINE: âœ… BOM\n",
      "   Features finais: 49\n",
      "   Pronto para modelagem: SIM\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ PIPELINE EXPLÃCITO CONCLUÃDO COM SUCESSO!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# AUDITORIA COMPLETA DO PIPELINE\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ” AUDITORIA COMPLETA DO PIPELINE EXPLÃCITO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Coletar todos os resultados de auditoria\n",
    "pipeline_steps = [\n",
    "    audit_step01, audit_step02, audit_step03, \n",
    "    audit_step04, audit_step05, audit_step06, audit_step07\n",
    "]\n",
    "\n",
    "# Tabela resumo\n",
    "print(f\"\\nğŸ“Š RESUMO COMPLETO DO PIPELINE:\")\n",
    "print(f\"{'Step':<25} {'Shape':<15} {'Features':<10} {'TÃ©cnicas':<10} {'Shifted':<10} {'Candlestick':<12}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for step in pipeline_steps:\n",
    "    step_name = step['step_name'][:23] + '...' if len(step['step_name']) > 25 else step['step_name']\n",
    "    shape_str = f\"{step['shape'][0]}x{step['shape'][1]}\"\n",
    "    print(f\"{step_name:<25} {shape_str:<15} {step['shape'][1]:<10} {step['technical_count']:<10} {step['shifted_count']:<10} {step['candlestick_count']:<12}\")\n",
    "\n",
    "# AnÃ¡lise de evoluÃ§Ã£o\n",
    "print(f\"\\nğŸ“ˆ EVOLUÃ‡ÃƒO DAS FEATURES:\")\n",
    "for i in range(1, len(pipeline_steps)):\n",
    "    prev_step = pipeline_steps[i-1]\n",
    "    curr_step = pipeline_steps[i]\n",
    "    \n",
    "    change = curr_step['shape'][1] - prev_step['shape'][1]\n",
    "    change_str = f\"{change:+d}\" if change != 0 else \"0\"\n",
    "    \n",
    "    print(f\"   {prev_step['step_name']} â†’ {curr_step['step_name']}: {change_str} features\")\n",
    "\n",
    "# Identificar penhascos\n",
    "print(f\"\\nğŸš¨ IDENTIFICAÃ‡ÃƒO DE PENHASCOS:\")\n",
    "penhascos_encontrados = []\n",
    "\n",
    "for i in range(1, len(pipeline_steps)):\n",
    "    prev_step = pipeline_steps[i-1]\n",
    "    curr_step = pipeline_steps[i]\n",
    "    \n",
    "    loss = prev_step['shape'][1] - curr_step['shape'][1]\n",
    "    if loss > 5:  # Perda significativa\n",
    "        penhascos_encontrados.append({\n",
    "            'from': prev_step['step_name'],\n",
    "            'to': curr_step['step_name'],\n",
    "            'loss': loss\n",
    "        })\n",
    "\n",
    "if penhascos_encontrados:\n",
    "    print(f\"   âŒ {len(penhascos_encontrados)} penhasco(s) identificado(s):\")\n",
    "    for penhasco in penhascos_encontrados:\n",
    "        print(f\"      {penhasco['from']} â†’ {penhasco['to']}: -{penhasco['loss']} features\")\n",
    "else:\n",
    "    print(f\"   âœ… Nenhum penhasco significativo identificado\")\n",
    "\n",
    "# VerificaÃ§Ã£o final\n",
    "print(f\"\\nâœ… VERIFICAÃ‡ÃƒO FINAL:\")\n",
    "print(f\"   Dataset inicial: {pipeline_steps[0]['shape']}\")\n",
    "print(f\"   Dataset final: {pipeline_steps[-1]['shape']}\")\n",
    "print(f\"   Features criadas: {pipeline_steps[-1]['shape'][1] - pipeline_steps[0]['shape'][1]:+d}\")\n",
    "print(f\"   Linhas preservadas: {pipeline_steps[-1]['shape'][0] / pipeline_steps[0]['shape'][0]:.1%}\")\n",
    "\n",
    "# Status do pipeline\n",
    "final_features = pipeline_steps[-1]['shape'][1]\n",
    "if final_features >= 50:\n",
    "    status = \"âœ… EXCELENTE\"\n",
    "elif final_features >= 30:\n",
    "    status = \"âœ… BOM\"\n",
    "elif final_features >= 20:\n",
    "    status = \"âš ï¸ ACEITÃVEL\"\n",
    "else:\n",
    "    status = \"âŒ INSUFICIENTE\"\n",
    "\n",
    "print(f\"\\nğŸ¯ STATUS DO PIPELINE: {status}\")\n",
    "print(f\"   Features finais: {final_features}\")\n",
    "print(f\"   Pronto para modelagem: {'SIM' if final_features >= 20 else 'NÃƒO'}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"ğŸš€ PIPELINE EXPLÃCITO CONCLUÃDO COM SUCESSO!\")\n",
    "print(f\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPORTAR DATASET FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ EXPORTANDO DATASET FINAL...\n",
      "âœ… Dataset exportado: dataset_final_pipeline_explicito.csv\n",
      "ğŸ“Š Shape: (3586, 49)\n",
      "ğŸ“‹ Features: ['Data', 'day_of_week', 'month', 'quarter', 'year', 'is_month_start', 'is_month_end', 'is_quarter_end', 'Target', 'Abertura_shifted', 'MÃ¡xima_shifted', 'MÃ­nima_shifted', 'Ãšltimo_shifted', 'Volume_shifted', 'MA_5_shifted', 'MA_10_shifted', 'MA_20_shifted', 'MA_50_shifted', 'BB_Upper_shifted', 'BB_Lower_shifted', 'BB_Width_shifted', 'BB_Position_shifted', 'RSI_shifted', 'MACD_shifted', 'Signal_Line_shifted', 'atr_5_shifted', 'atr_10_shifted', 'atr_20_shifted', 'volatility_5_shifted', 'volatility_10_shifted', 'volatility_20_shifted', 'Price_Range_shifted', 'Price_Position_shifted', 'Gap_shifted', 'hl_close_ratio_shifted', 'true_range_shifted', 'high_close_prev_shifted', 'low_close_prev_shifted', 'returns_shifted', 'Variacao_shifted', 'doji_prev', 'hammer_prev', 'shooting_star_prev', 'engulfing_bullish_prev', 'bullish_candle_prev', 'bearish_candle_prev', 'body_size_prev', 'upper_shadow_prev', 'lower_shadow_prev']\n",
      "âœ… RelatÃ³rio criado: relatorio_features_pipeline.txt\n",
      "\n",
      "ğŸ‰ PIPELINE EXPLÃCITO CONCLUÃDO COM SUCESSO!\n",
      "ğŸ“Š 49 features preservadas e prontas para modelagem\n"
     ]
    }
   ],
   "source": [
    "# EXPORTAR DATASET FINAL\n",
    "print(\"\\nğŸ’¾ EXPORTANDO DATASET FINAL...\")\n",
    "\n",
    "# Salvar dataset final\n",
    "output_filename = 'dataset_final_pipeline_explicito.csv'\n",
    "df_step07_final.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"âœ… Dataset exportado: {output_filename}\")\n",
    "print(f\"ğŸ“Š Shape: {df_step07_final.shape}\")\n",
    "print(f\"ğŸ“‹ Features: {list(df_step07_final.columns)}\")\n",
    "\n",
    "# Criar relatÃ³rio de features\n",
    "report_filename = 'relatorio_features_pipeline.txt'\n",
    "with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"RELATÃ“RIO DE FEATURES - PIPELINE EXPLÃCITO\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Dataset Final: {df_step07_final.shape}\\n\\n\")\n",
    "    \n",
    "    f.write(\"FEATURES POR CATEGORIA:\\n\")\n",
    "    f.write(\"-\" * 30 + \"\\n\")\n",
    "    \n",
    "    # Categorizar features finais\n",
    "    final_cols = df_step07_final.columns\n",
    "    \n",
    "    ohlc_final = [col for col in final_cols if any(x in col for x in ['Abertura', 'MÃ¡xima', 'MÃ­nima', 'Ãšltimo', 'Volume'])]\n",
    "    temporal_final = [col for col in final_cols if any(x in col.lower() for x in ['data', 'day', 'month', 'quarter', 'year'])]\n",
    "    technical_final = [col for col in final_cols if any(x in col.lower() for x in ['ma_', 'bb_', 'rsi', 'atr', 'volatility', 'macd'])]\n",
    "    shifted_final = [col for col in final_cols if col.endswith('_shifted')]\n",
    "    candlestick_final = [col for col in final_cols if any(x in col.lower() for x in ['doji', 'hammer', 'engulf', 'prev'])]\n",
    "    target_final = [col for col in final_cols if 'target' in col.lower()]\n",
    "    \n",
    "    f.write(f\"OHLC/Volume ({len(ohlc_final)}): {ohlc_final}\\n\\n\")\n",
    "    f.write(f\"Temporais ({len(temporal_final)}): {temporal_final}\\n\\n\")\n",
    "    f.write(f\"TÃ©cnicas ({len(technical_final)}): {technical_final}\\n\\n\")\n",
    "    f.write(f\"Shifted ({len(shifted_final)}): {shifted_final}\\n\\n\")\n",
    "    f.write(f\"Candlestick ({len(candlestick_final)}): {candlestick_final}\\n\\n\")\n",
    "    f.write(f\"Target ({len(target_final)}): {target_final}\\n\\n\")\n",
    "\n",
    "print(f\"âœ… RelatÃ³rio criado: {report_filename}\")\n",
    "print(f\"\\nğŸ‰ PIPELINE EXPLÃCITO CONCLUÃDO COM SUCESSO!\")\n",
    "print(f\"ğŸ“Š {df_step07_final.shape[1]} features preservadas e prontas para modelagem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ† OLIMPÃADA DE MODELOS: TESTE COMPLETO DE ALGORITMOS\n",
    "\n",
    "## Objetivo Duplo:\n",
    "1. **Encontrar o algoritmo de melhor performance**\n",
    "2. **Verificar se features de candlestick agregam valor preditivo**\n",
    "\n",
    "## EstratÃ©gia de Teste:\n",
    "- **Dataset A (Baseline)**: ~40 features (STEP 05 - sem candlestick)\n",
    "- **Dataset B (Enriquecido)**: ~49 features (STEP 07 - com candlestick)\n",
    "\n",
    "## Categorias de Modelos:\n",
    "1. **Baseline Linear**: RegressÃ£o LogÃ­stica\n",
    "2. **Ensembles de Ãrvores**: Random Forest, XGBoost, LightGBM\n",
    "3. **NÃ£o-Lineares**: SVM (RBF)\n",
    "4. **Ensemble HÃ­brido**: Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† === OLIMPÃADA DE MODELOS === ğŸ†\n",
      "\n",
      "Preparando framework de testes completo...\n",
      "âœ… Framework de avaliaÃ§Ã£o preparado\n",
      "ğŸ Pronto para iniciar a competiÃ§Ã£o!\n"
     ]
    }
   ],
   "source": [
    "# PREPARAÃ‡ÃƒO PARA OLIMPÃADA DE MODELOS\n",
    "print(\"ğŸ† === OLIMPÃADA DE MODELOS === ğŸ†\")\n",
    "print()\n",
    "print(\"Preparando framework de testes completo...\")\n",
    "\n",
    "# Imports necessÃ¡rios\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# FunÃ§Ã£o para avaliaÃ§Ã£o completa de modelos\n",
    "def evaluate_model_complete(model, X_train, X_test, y_train, y_test, model_name, dataset_name):\n",
    "    \"\"\"\n",
    "    AvaliaÃ§Ã£o completa de um modelo com mÃºltiplas mÃ©tricas\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Treinar modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # PrediÃ§Ãµes\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # MÃ©tricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "    \n",
    "    # Tempo de treinamento\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Cross-validation com TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=tscv, scoring='accuracy')\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'dataset': dataset_name,\n",
    "        'accuracy': accuracy,\n",
    "        'auc_score': auc_score,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'training_time': training_time,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "# FunÃ§Ã£o para preparar datasets\n",
    "def prepare_datasets():\n",
    "    \"\"\"\n",
    "    Prepara Dataset A (baseline) e Dataset B (enriquecido)\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“Š Preparando datasets para competiÃ§Ã£o...\")\n",
    "    \n",
    "    # Dataset A (Baseline) - STEP 05 (sem candlestick)\n",
    "    dataset_a = df_step05_temporal.copy()\n",
    "    \n",
    "    # Dataset B (Enriquecido) - STEP 07 (com candlestick)\n",
    "    dataset_b = df_step07_final.copy()\n",
    "    \n",
    "    print(f\"   Dataset A (Baseline): {dataset_a.shape}\")\n",
    "    print(f\"   Dataset B (Enriquecido): {dataset_b.shape}\")\n",
    "    print(f\"   DiferenÃ§a: +{dataset_b.shape[1] - dataset_a.shape[1]} features no Dataset B\")\n",
    "    \n",
    "    return dataset_a, dataset_b\n",
    "\n",
    "# FunÃ§Ã£o para split temporal\n",
    "def create_temporal_split(df, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Cria split temporal respeitando ordem cronolÃ³gica\n",
    "    \"\"\"\n",
    "    # Ordenar por data se disponÃ­vel\n",
    "    if 'Data' in df.columns:\n",
    "        df_sorted = df.sort_values('Data').reset_index(drop=True)\n",
    "    else:\n",
    "        df_sorted = df.copy()\n",
    "    \n",
    "    # Split temporal\n",
    "    split_idx = int(len(df_sorted) * (1 - test_size))\n",
    "    \n",
    "    train_df = df_sorted.iloc[:split_idx]\n",
    "    test_df = df_sorted.iloc[split_idx:]\n",
    "    \n",
    "    # Separar features e target\n",
    "    feature_cols = [col for col in df_sorted.columns if col not in ['Data', 'Target']]\n",
    "    \n",
    "    X_train = train_df[feature_cols]\n",
    "    X_test = test_df[feature_cols]\n",
    "    y_train = train_df['Target']\n",
    "    y_test = test_df['Target']\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "print(\"âœ… Framework de avaliaÃ§Ã£o preparado\")\n",
    "print(\"ğŸ Pronto para iniciar a competiÃ§Ã£o!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARAÃ‡ÃƒO DOS DATASETS E COMPETIDORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š === PREPARAÃ‡ÃƒO DOS DATASETS === ğŸ“Š\n",
      "ğŸ“Š Preparando datasets para competiÃ§Ã£o...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_step05_temporal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ“Š === PREPARAÃ‡ÃƒO DOS DATASETS === ğŸ“Š\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Preparar datasets A e B\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m dataset_a, dataset_b = \u001b[43mprepare_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Criar splits temporais para ambos datasets\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mğŸ”„ Criando splits temporais...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mprepare_datasets\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ“Š Preparando datasets para competiÃ§Ã£o...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Dataset A (Baseline) - STEP 05 (sem candlestick)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m dataset_a = \u001b[43mdf_step05_temporal\u001b[49m.copy()\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Dataset B (Enriquecido) - STEP 07 (com candlestick)\u001b[39;00m\n\u001b[32m     70\u001b[39m dataset_b = df_step07_final.copy()\n",
      "\u001b[31mNameError\u001b[39m: name 'df_step05_temporal' is not defined"
     ]
    }
   ],
   "source": [
    "# PREPARAÃ‡ÃƒO DOS DATASETS\n",
    "print(\"ğŸ“Š === PREPARAÃ‡ÃƒO DOS DATASETS === ğŸ“Š\")\n",
    "\n",
    "# Preparar datasets A e B\n",
    "dataset_a, dataset_b = prepare_datasets()\n",
    "\n",
    "# Criar splits temporais para ambos datasets\n",
    "print(f\"\\nğŸ”„ Criando splits temporais...\")\n",
    "\n",
    "X_train_a, X_test_a, y_train_a, y_test_a = create_temporal_split(dataset_a)\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = create_temporal_split(dataset_b)\n",
    "\n",
    "print(f\"\\nğŸ“‹ RESUMO DOS SPLITS:\")\n",
    "print(f\"Dataset A - Train: {X_train_a.shape}, Test: {X_test_a.shape}\")\n",
    "print(f\"Dataset B - Train: {X_train_b.shape}, Test: {X_test_b.shape}\")\n",
    "\n",
    "# Verificar distribuiÃ§Ã£o do target\n",
    "print(f\"\\nğŸ¯ DISTRIBUIÃ‡ÃƒO DO TARGET:\")\n",
    "print(f\"Dataset A - Train: {y_train_a.value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"Dataset A - Test: {y_test_a.value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"Dataset B - Train: {y_train_b.value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"Dataset B - Test: {y_test_b.value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "# Preparar competidores\n",
    "print(f\"\\nğŸ† === PREPARAÃ‡ÃƒO DOS COMPETIDORES === ğŸ†\")\n",
    "\n",
    "# Categoria 1: Baseline Linear\n",
    "competitors = {\n",
    "    'RegressÃ£o LogÃ­stica': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('logreg', LogisticRegression(C=0.1, solver='liblinear', random_state=42))\n",
    "    ]),\n",
    "    \n",
    "    # Categoria 2: Ensembles de Ãrvores\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \n",
    "    'XGBoost': xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    ),\n",
    "    \n",
    "    'LightGBM': lgb.LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    \n",
    "    # Categoria 3: NÃ£o-Lineares\n",
    "    'SVM (RBF)': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(kernel='rbf', probability=True, random_state=42, C=1.0))\n",
    "    ])\n",
    "}\n",
    "\n",
    "print(f\"âœ… {len(competitors)} competidores preparados:\")\n",
    "for name in competitors.keys():\n",
    "    print(f\"   ğŸ¤– {name}\")\n",
    "\n",
    "print(f\"\\nğŸš€ Tudo pronto para a OlimpÃ­ada de Modelos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXECUÃ‡ÃƒO DA OLIMPÃADA DE MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUÃ‡ÃƒO DA OLIMPÃADA DE MODELOS\n",
    "print(\"ğŸ† === INICIANDO OLIMPÃADA DE MODELOS === ğŸ†\")\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print()\n",
    "\n",
    "# Armazenar todos os resultados\n",
    "all_results = []\n",
    "\n",
    "# Executar cada modelo em ambos datasets\n",
    "for model_name, model in competitors.items():\n",
    "    print(f\"\\nğŸ¤– === TESTANDO: {model_name.upper()} === ğŸ¤–\")\n",
    "    \n",
    "    # Teste no Dataset A (Baseline)\n",
    "    print(f\"\\nğŸ“Š Dataset A (Baseline - {X_train_a.shape[1]} features):\")\n",
    "    try:\n",
    "        result_a = evaluate_model_complete(\n",
    "            model, X_train_a, X_test_a, y_train_a, y_test_a, \n",
    "            model_name, \"Dataset A (Baseline)\"\n",
    "        )\n",
    "        all_results.append(result_a)\n",
    "        \n",
    "        print(f\"   âœ… Accuracy: {result_a['accuracy']:.4f}\")\n",
    "        print(f\"   ğŸ“ˆ AUC: {result_a['auc_score']:.4f}\" if result_a['auc_score'] else \"   ğŸ“ˆ AUC: N/A\")\n",
    "        print(f\"   ğŸ”„ CV Mean: {result_a['cv_mean']:.4f} (Â±{result_a['cv_std']:.4f})\")\n",
    "        print(f\"   â±ï¸ Tempo: {result_a['training_time']:.2f}s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Erro no Dataset A: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Teste no Dataset B (Enriquecido)\n",
    "    print(f\"\\nğŸ“Š Dataset B (Enriquecido - {X_train_b.shape[1]} features):\")\n",
    "    try:\n",
    "        result_b = evaluate_model_complete(\n",
    "            model, X_train_b, X_test_b, y_train_b, y_test_b, \n",
    "            model_name, \"Dataset B (Enriquecido)\"\n",
    "        )\n",
    "        all_results.append(result_b)\n",
    "        \n",
    "        print(f\"   âœ… Accuracy: {result_b['accuracy']:.4f}\")\n",
    "        print(f\"   ğŸ“ˆ AUC: {result_b['auc_score']:.4f}\" if result_b['auc_score'] else \"   ğŸ“ˆ AUC: N/A\")\n",
    "        print(f\"   ğŸ”„ CV Mean: {result_b['cv_mean']:.4f} (Â±{result_b['cv_std']:.4f})\")\n",
    "        print(f\"   â±ï¸ Tempo: {result_b['training_time']:.2f}s\")\n",
    "        \n",
    "        # Comparar com Dataset A\n",
    "        accuracy_diff = result_b['accuracy'] - result_a['accuracy']\n",
    "        auc_diff = (result_b['auc_score'] - result_a['auc_score']) if (result_b['auc_score'] and result_a['auc_score']) else None\n",
    "        \n",
    "        print(f\"\\nğŸ“Š COMPARAÃ‡ÃƒO (B vs A):\")\n",
    "        print(f\"   ğŸ“ˆ Accuracy: {accuracy_diff:+.4f} ({'âœ… Melhora' if accuracy_diff > 0 else 'âŒ Piora' if accuracy_diff < 0 else 'â– Igual'})\")\n",
    "        if auc_diff is not None:\n",
    "            print(f\"   ğŸ“ˆ AUC: {auc_diff:+.4f} ({'âœ… Melhora' if auc_diff > 0 else 'âŒ Piora' if auc_diff < 0 else 'â– Igual'})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Erro no Dataset B: {e}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "\n",
    "print(f\"\\nğŸ OLIMPÃADA CONCLUÃDA!\")\n",
    "print(f\"ğŸ“Š Total de resultados coletados: {len(all_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANÃLISE COMPLETA DOS RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÃLISE COMPLETA DOS RESULTADOS\n",
    "print(\"ğŸ“Š === ANÃLISE COMPLETA DOS RESULTADOS === ğŸ“Š\")\n",
    "print()\n",
    "\n",
    "if len(all_results) > 0:\n",
    "    # Criar DataFrame com resultados\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Tabela de resultados\n",
    "    print(\"ğŸ† TABELA DE RESULTADOS COMPLETA:\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"{'Modelo':<20} {'Dataset':<25} {'Accuracy':<10} {'AUC':<8} {'CV Mean':<10} {'CV Std':<8} {'Tempo(s)':<8}\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    for _, row in results_df.iterrows():\n",
    "        auc_str = f\"{row['auc_score']:.4f}\" if row['auc_score'] is not None else \"N/A\"\n",
    "        print(f\"{row['model_name']:<20} {row['dataset']:<25} {row['accuracy']:<10.4f} {auc_str:<8} {row['cv_mean']:<10.4f} {row['cv_std']:<8.4f} {row['training_time']:<8.2f}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # AnÃ¡lise por dataset\n",
    "    print(\"ğŸ“Š RANKING POR DATASET:\")\n",
    "    print()\n",
    "    \n",
    "    for dataset in ['Dataset A (Baseline)', 'Dataset B (Enriquecido)']:\n",
    "        dataset_results = results_df[results_df['dataset'] == dataset].copy()\n",
    "        if len(dataset_results) > 0:\n",
    "            dataset_results = dataset_results.sort_values('accuracy', ascending=False)\n",
    "            \n",
    "            print(f\"ğŸ… {dataset}:\")\n",
    "            for i, (_, row) in enumerate(dataset_results.iterrows(), 1):\n",
    "                medal = \"ğŸ¥‡\" if i == 1 else \"ğŸ¥ˆ\" if i == 2 else \"ğŸ¥‰\" if i == 3 else f\"{i}Âº\"\n",
    "                auc_str = f\"AUC: {row['auc_score']:.4f}\" if row['auc_score'] is not None else \"AUC: N/A\"\n",
    "                print(f\"   {medal} {row['model_name']}: Acc: {row['accuracy']:.4f}, {auc_str}\")\n",
    "            print()\n",
    "    \n",
    "    # AnÃ¡lise do impacto das features de candlestick\n",
    "    print(\"ğŸ•¯ï¸ ANÃLISE DO IMPACTO DAS FEATURES DE CANDLESTICK:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    candlestick_impact = []\n",
    "    \n",
    "    for model_name in results_df['model_name'].unique():\n",
    "        model_results = results_df[results_df['model_name'] == model_name]\n",
    "        \n",
    "        if len(model_results) == 2:  # Tem resultado para ambos datasets\n",
    "            baseline = model_results[model_results['dataset'] == 'Dataset A (Baseline)'].iloc[0]\n",
    "            enriched = model_results[model_results['dataset'] == 'Dataset B (Enriquecido)'].iloc[0]\n",
    "            \n",
    "            accuracy_improvement = enriched['accuracy'] - baseline['accuracy']\n",
    "            auc_improvement = (enriched['auc_score'] - baseline['auc_score']) if (enriched['auc_score'] and baseline['auc_score']) else None\n",
    "            \n",
    "            candlestick_impact.append({\n",
    "                'model': model_name,\n",
    "                'accuracy_improvement': accuracy_improvement,\n",
    "                'auc_improvement': auc_improvement,\n",
    "                'baseline_accuracy': baseline['accuracy'],\n",
    "                'enriched_accuracy': enriched['accuracy']\n",
    "            })\n",
    "            \n",
    "            impact_symbol = \"âœ…\" if accuracy_improvement > 0.01 else \"âš ï¸\" if accuracy_improvement > 0 else \"âŒ\"\n",
    "            print(f\"{impact_symbol} {model_name}:\")\n",
    "            print(f\"   Accuracy: {baseline['accuracy']:.4f} â†’ {enriched['accuracy']:.4f} ({accuracy_improvement:+.4f})\")\n",
    "            if auc_improvement is not None:\n",
    "                print(f\"   AUC: {baseline['auc_score']:.4f} â†’ {enriched['auc_score']:.4f} ({auc_improvement:+.4f})\")\n",
    "            print()\n",
    "    \n",
    "    # Resumo do impacto das features de candlestick\n",
    "    if candlestick_impact:\n",
    "        avg_accuracy_improvement = np.mean([x['accuracy_improvement'] for x in candlestick_impact])\n",
    "        positive_improvements = sum(1 for x in candlestick_impact if x['accuracy_improvement'] > 0)\n",
    "        \n",
    "        print(f\"ğŸ“ˆ RESUMO DO IMPACTO DAS FEATURES DE CANDLESTICK:\")\n",
    "        print(f\"   Melhoria mÃ©dia de accuracy: {avg_accuracy_improvement:+.4f}\")\n",
    "        print(f\"   Modelos que melhoraram: {positive_improvements}/{len(candlestick_impact)}\")\n",
    "        \n",
    "        if avg_accuracy_improvement > 0.01:\n",
    "            conclusion = \"âœ… FEATURES DE CANDLESTICK AGREGAM VALOR SIGNIFICATIVO\"\n",
    "        elif avg_accuracy_improvement > 0:\n",
    "            conclusion = \"âš ï¸ FEATURES DE CANDLESTICK AGREGAM VALOR MARGINAL\"\n",
    "        else:\n",
    "            conclusion = \"âŒ FEATURES DE CANDLESTICK NÃƒO AGREGAM VALOR\"\n",
    "        \n",
    "        print(f\"\\nğŸ¯ CONCLUSÃƒO: {conclusion}\")\n",
    "    \n",
    "    # Identificar o campeÃ£o geral\n",
    "    print(f\"\\nğŸ† CAMPEÃƒO GERAL:\")\n",
    "    best_result = results_df.loc[results_df['accuracy'].idxmax()]\n",
    "    print(f\"   ğŸ¥‡ {best_result['model_name']} no {best_result['dataset']}\")\n",
    "    print(f\"   ğŸ“Š Accuracy: {best_result['accuracy']:.4f}\")\n",
    "    print(f\"   ğŸ“ˆ AUC: {best_result['auc_score']:.4f}\" if best_result['auc_score'] else \"   ğŸ“ˆ AUC: N/A\")\n",
    "    print(f\"   ğŸ”„ CV: {best_result['cv_mean']:.4f} (Â±{best_result['cv_std']:.4f})\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Nenhum resultado coletado. Verifique a execuÃ§Ã£o dos modelos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENSEMBLE HÃBRIDO: COMBINANDO OS MELHORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSEMBLE HÃBRIDO: COMBINANDO OS MELHORES\n",
    "print(\"ğŸ¤ === ENSEMBLE HÃBRIDO: COMBINANDO OS MELHORES === ğŸ¤\")\n",
    "print()\n",
    "\n",
    "if len(all_results) >= 3:\n",
    "    # Identificar os 3 melhores modelos no Dataset B\n",
    "    dataset_b_results = [r for r in all_results if r['dataset'] == 'Dataset B (Enriquecido)']\n",
    "    \n",
    "    if len(dataset_b_results) >= 3:\n",
    "        # Ordenar por accuracy\n",
    "        dataset_b_results.sort(key=lambda x: x['accuracy'], reverse=True)\n",
    "        top_3 = dataset_b_results[:3]\n",
    "        \n",
    "        print(f\"ğŸ… TOP 3 MODELOS SELECIONADOS PARA ENSEMBLE:\")\n",
    "        for i, result in enumerate(top_3, 1):\n",
    "            print(f\"   {i}Âº {result['model_name']}: {result['accuracy']:.4f}\")\n",
    "        \n",
    "        # Criar Voting Classifier com os top 3\n",
    "        ensemble_estimators = []\n",
    "        \n",
    "        for result in top_3:\n",
    "            model_name = result['model_name']\n",
    "            model = result['model']\n",
    "            \n",
    "            # Criar nome Ãºnico para o ensemble\n",
    "            ensemble_name = model_name.lower().replace(' ', '_').replace('(', '').replace(')', '')\n",
    "            ensemble_estimators.append((ensemble_name, model))\n",
    "        \n",
    "        # Criar Voting Classifier\n",
    "        voting_classifier = VotingClassifier(\n",
    "            estimators=ensemble_estimators,\n",
    "            voting='soft'  # Usa probabilidades\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nğŸ¤– Testando Voting Classifier (Soft Voting)...\")\n",
    "        \n",
    "        # Testar ensemble no Dataset B\n",
    "        try:\n",
    "            ensemble_result = evaluate_model_complete(\n",
    "                voting_classifier, X_train_b, X_test_b, y_train_b, y_test_b,\n",
    "                \"Voting Classifier\", \"Dataset B (Enriquecido)\"\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nğŸ“Š RESULTADO DO ENSEMBLE:\")\n",
    "            print(f\"   âœ… Accuracy: {ensemble_result['accuracy']:.4f}\")\n",
    "            print(f\"   ğŸ“ˆ AUC: {ensemble_result['auc_score']:.4f}\")\n",
    "            print(f\"   ğŸ”„ CV Mean: {ensemble_result['cv_mean']:.4f} (Â±{ensemble_result['cv_std']:.4f})\")\n",
    "            print(f\"   â±ï¸ Tempo: {ensemble_result['training_time']:.2f}s\")\n",
    "            \n",
    "            # Comparar com o melhor individual\n",
    "            best_individual = top_3[0]\n",
    "            improvement = ensemble_result['accuracy'] - best_individual['accuracy']\n",
    "            \n",
    "            print(f\"\\nğŸ†š ENSEMBLE vs MELHOR INDIVIDUAL:\")\n",
    "            print(f\"   Melhor individual: {best_individual['model_name']} ({best_individual['accuracy']:.4f})\")\n",
    "            print(f\"   Ensemble: {ensemble_result['accuracy']:.4f}\")\n",
    "            print(f\"   DiferenÃ§a: {improvement:+.4f} ({'âœ… Melhora' if improvement > 0 else 'âŒ Piora' if improvement < 0 else 'â– Igual'})\")\n",
    "            \n",
    "            # Adicionar resultado do ensemble Ã  lista\n",
    "            all_results.append(ensemble_result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro ao criar ensemble: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"âš ï¸ Poucos resultados no Dataset B para criar ensemble\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Poucos resultados coletados para criar ensemble\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZAÃ‡Ã•ES E RELATÃ“RIO FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZAÃ‡Ã•ES E RELATÃ“RIO FINAL\n",
    "print(\"ğŸ“Š === VISUALIZAÃ‡Ã•ES E RELATÃ“RIO FINAL === ğŸ“Š\")\n",
    "print()\n",
    "\n",
    "if len(all_results) > 0:\n",
    "    # Criar DataFrame atualizado com ensemble\n",
    "    final_results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # GrÃ¡fico de comparaÃ§Ã£o de accuracy\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Subplot 1: ComparaÃ§Ã£o de Accuracy por Modelo e Dataset\n",
    "    plt.subplot(2, 2, 1)\n",
    "    \n",
    "    # Preparar dados para o grÃ¡fico\n",
    "    models = final_results_df['model_name'].unique()\n",
    "    datasets = final_results_df['dataset'].unique()\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    for i, dataset in enumerate(datasets):\n",
    "        dataset_data = final_results_df[final_results_df['dataset'] == dataset]\n",
    "        accuracies = []\n",
    "        \n",
    "        for model in models:\n",
    "            model_data = dataset_data[dataset_data['model_name'] == model]\n",
    "            if len(model_data) > 0:\n",
    "                accuracies.append(model_data.iloc[0]['accuracy'])\n",
    "            else:\n",
    "                accuracies.append(0)\n",
    "        \n",
    "        plt.bar(x + i*width, accuracies, width, label=dataset, alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Modelos')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('ComparaÃ§Ã£o de Accuracy por Modelo e Dataset')\n",
    "    plt.xticks(x + width/2, models, rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 2: Impacto das Features de Candlestick\n",
    "    plt.subplot(2, 2, 2)\n",
    "    \n",
    "    if len(candlestick_impact) > 0:\n",
    "        models_impact = [x['model'] for x in candlestick_impact]\n",
    "        improvements = [x['accuracy_improvement'] for x in candlestick_impact]\n",
    "        \n",
    "        colors = ['green' if x > 0 else 'red' for x in improvements]\n",
    "        plt.bar(models_impact, improvements, color=colors, alpha=0.7)\n",
    "        plt.xlabel('Modelos')\n",
    "        plt.ylabel('Melhoria de Accuracy')\n",
    "        plt.title('Impacto das Features de Candlestick')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 3: DistribuiÃ§Ã£o de AUC\n",
    "    plt.subplot(2, 2, 3)\n",
    "    \n",
    "    auc_scores = [r['auc_score'] for r in all_results if r['auc_score'] is not None]\n",
    "    if auc_scores:\n",
    "        plt.hist(auc_scores, bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        plt.xlabel('AUC Score')\n",
    "        plt.ylabel('FrequÃªncia')\n",
    "        plt.title('DistribuiÃ§Ã£o de AUC Scores')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 4: Tempo de Treinamento\n",
    "    plt.subplot(2, 2, 4)\n",
    "    \n",
    "    model_names = [r['model_name'] for r in all_results]\n",
    "    training_times = [r['training_time'] for r in all_results]\n",
    "    \n",
    "    plt.scatter(training_times, [r['accuracy'] for r in all_results], alpha=0.7, s=100)\n",
    "    \n",
    "    for i, model in enumerate(model_names):\n",
    "        plt.annotate(model[:10], (training_times[i], all_results[i]['accuracy']), \n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    \n",
    "    plt.xlabel('Tempo de Treinamento (s)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs Tempo de Treinamento')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # RelatÃ³rio final em texto\n",
    "    print(f\"\\nğŸ“‹ === RELATÃ“RIO FINAL DA OLIMPÃADA === ğŸ“‹\")\n",
    "    print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"=\"*60)\n",
    "    \n",
    "    # CampeÃ£o absoluto\n",
    "    best_overall = final_results_df.loc[final_results_df['accuracy'].idxmax()]\n",
    "    print(f\"\\nğŸ† CAMPEÃƒO ABSOLUTO:\")\n",
    "    print(f\"   Modelo: {best_overall['model_name']}\")\n",
    "    print(f\"   Dataset: {best_overall['dataset']}\")\n",
    "    print(f\"   Accuracy: {best_overall['accuracy']:.4f}\")\n",
    "    print(f\"   AUC: {best_overall['auc_score']:.4f}\" if best_overall['auc_score'] else \"   AUC: N/A\")\n",
    "    \n",
    "    # Melhor por categoria\n",
    "    print(f\"\\nğŸ… MELHORES POR CATEGORIA:\")\n",
    "    \n",
    "    categories = {\n",
    "        'Linear': ['RegressÃ£o LogÃ­stica'],\n",
    "        'Ãrvores': ['Random Forest', 'XGBoost', 'LightGBM'],\n",
    "        'NÃ£o-Linear': ['SVM (RBF)'],\n",
    "        'Ensemble': ['Voting Classifier']\n",
    "    }\n",
    "    \n",
    "    for category, models in categories.items():\n",
    "        category_results = final_results_df[final_results_df['model_name'].isin(models)]\n",
    "        if len(category_results) > 0:\n",
    "            best_in_category = category_results.loc[category_results['accuracy'].idxmax()]\n",
    "            print(f\"   {category}: {best_in_category['model_name']} ({best_in_category['accuracy']:.4f})\")\n",
    "    \n",
    "    # ConclusÃ£o sobre features de candlestick\n",
    "    if candlestick_impact:\n",
    "        avg_improvement = np.mean([x['accuracy_improvement'] for x in candlestick_impact])\n",
    "        print(f\"\\nğŸ•¯ï¸ CONCLUSÃƒO SOBRE FEATURES DE CANDLESTICK:\")\n",
    "        print(f\"   Melhoria mÃ©dia: {avg_improvement:+.4f}\")\n",
    "        \n",
    "        if avg_improvement > 0.01:\n",
    "            print(f\"   âœ… RECOMENDAÃ‡ÃƒO: Usar features de candlestick (melhoria significativa)\")\n",
    "        elif avg_improvement > 0:\n",
    "            print(f\"   âš ï¸ RECOMENDAÃ‡ÃƒO: Considerar features de candlestick (melhoria marginal)\")\n",
    "        else:\n",
    "            print(f\"   âŒ RECOMENDAÃ‡ÃƒO: NÃ£o usar features de candlestick (sem benefÃ­cio)\")\n",
    "    \n",
    "    # RecomendaÃ§Ã£o final\n",
    "    print(f\"\\nğŸ¯ RECOMENDAÃ‡ÃƒO FINAL PARA PRODUÃ‡ÃƒO:\")\n",
    "    print(f\"   Modelo: {best_overall['model_name']}\")\n",
    "    print(f\"   Dataset: {best_overall['dataset']}\")\n",
    "    print(f\"   Justificativa: Melhor accuracy ({best_overall['accuracy']:.4f}) na competiÃ§Ã£o\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ OLIMPÃADA DE MODELOS CONCLUÃDA COM SUCESSO!\")\n",
    "    print(f\"=\"*60)\n",
    "\n",
    "else:\n",
    "    print(f\"âŒ Nenhum resultado disponÃ­vel para anÃ¡lise\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
